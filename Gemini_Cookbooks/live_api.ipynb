{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ai21 3.0.1 requires httpx<0.28.0,>=0.27.0, but you have httpx 0.28.1 which is incompatible.\n",
      "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.0 which is incompatible.\n",
      "e2b 1.0.5 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
      "gradio 5.9.1 requires aiofiles<24.0,>=22.0, but you have aiofiles 24.1.0 which is incompatible.\n",
      "litellm 1.60.2 requires httpx<0.28.0,>=0.23.0, but you have httpx 0.28.1 which is incompatible.\n",
      "llama-index-llms-huggingface 0.4.1 requires huggingface-hub<0.24.0,>=0.23.0, but you have huggingface-hub 0.28.1 which is incompatible.\n",
      "open-webui 0.5.12 requires aiohttp==3.11.11, but you have aiohttp 3.11.14 which is incompatible.\n",
      "open-webui 0.5.12 requires boto3==1.35.53, but you have boto3 1.21.46 which is incompatible.\n",
      "open-webui 0.5.12 requires chromadb==0.6.2, but you have chromadb 0.5.23 which is incompatible.\n",
      "open-webui 0.5.12 requires google-generativeai==0.7.2, but you have google-generativeai 0.8.4 which is incompatible.\n",
      "open-webui 0.5.12 requires langchain==0.3.7, but you have langchain 0.3.19 which is incompatible.\n",
      "open-webui 0.5.12 requires langchain-community==0.3.7, but you have langchain-community 0.3.18 which is incompatible.\n",
      "open-webui 0.5.12 requires pypdf==4.3.1, but you have pypdf 5.3.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires aiohttp==3.9.5, but you have aiohttp 3.11.14 which is incompatible.\n",
      "pr-agent 0.2.4 requires anthropic[vertex]==0.39.0, but you have anthropic 0.49.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires boto3==1.33.6, but you have boto3 1.21.46 which is incompatible.\n",
      "pr-agent 0.2.4 requires certifi==2024.8.30, but you have certifi 2021.10.8 which is incompatible.\n",
      "pr-agent 0.2.4 requires fastapi==0.111.0, but you have fastapi 0.115.7 which is incompatible.\n",
      "pr-agent 0.2.4 requires google-cloud-aiplatform==1.38.0, but you have google-cloud-aiplatform 1.79.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires google-cloud-storage==2.10.0, but you have google-cloud-storage 2.19.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires google-generativeai==0.8.3, but you have google-generativeai 0.8.4 which is incompatible.\n",
      "pr-agent 0.2.4 requires gunicorn==22.0.0, but you have gunicorn 20.1.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires Jinja2==3.1.2, but you have jinja2 3.1.6 which is incompatible.\n",
      "pr-agent 0.2.4 requires litellm==1.52.12, but you have litellm 1.60.2 which is incompatible.\n",
      "pr-agent 0.2.4 requires openai==1.55.3, but you have openai 1.63.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires pydantic==2.8.2, but you have pydantic 2.9.2 which is incompatible.\n",
      "pr-agent 0.2.4 requires pytest==7.4.0, but you have pytest 8.3.4 which is incompatible.\n",
      "pr-agent 0.2.4 requires tenacity==8.2.3, but you have tenacity 8.5.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires tiktoken==0.8.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires uvicorn==0.22.0, but you have uvicorn 0.30.6 which is incompatible.\n",
      "pyautogen 0.6.1 requires asyncer>=0.0.8, but you have asyncer 0.0.7 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "client = genai.Client(http_options= {'api_version': 'v1alpha'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemini-2.0-flash-exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import contextlib\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import wave\n",
    "import itertools\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "async def async_enumerate(it):\n",
    "  n = 0\n",
    "  async for item in it:\n",
    "    yield n, item\n",
    "    n +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjaykumarKV\\AppData\\Local\\Temp\\ipykernel_21808\\687502328.py:4: ExperimentalWarning: The live API is experimental and may change in future versions.\n",
      "  async with client.aio.live.connect(model=MODEL, config=config) as session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Hello? Gemini are you there? \n",
      "\n",
      "- Yes\n",
      "- , I'm here! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config={\n",
    "    \"response_modalities\": [\"TEXT\"]}\n",
    "\n",
    "async with client.aio.live.connect(model=MODEL, config=config) as session:\n",
    "  message = \"Hello? Gemini are you there?\"\n",
    "  print(\"> \", message, \"\\n\")\n",
    "  await session.send(input=message, end_of_turn=True)\n",
    "\n",
    "  # For text responses, When the model's turn is complete it breaks out of the loop.\n",
    "  turn = session.receive()\n",
    "  async for chunk in turn:\n",
    "    if chunk.text is not None:\n",
    "      print(f'- {chunk.text}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
