{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-core\n",
    "%pip install llama-index-agent-openai\n",
    "%pip install llama-index-readers-file\n",
    "%pip install llama-index-postprocessor-cohere-rerank\n",
    "%pip install llama-index-llms-openai\n",
    "%pip install llama-index-embeddings-openai\n",
    "%pip install unstructured[html]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file import UnstructuredReader\n",
    "\n",
    "reader = UnstructuredReader(api_key=\"1cBV9jD9Ewap2ow3q2BEUeEz3EA57a\",url=\"https://api.unstructured.io/general/v0/general\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "all_files_gen = Path(\"./docs.llamaindex.ai/\").rglob(\"*\")\n",
    "all_files = [f.resolve() for f in all_files_gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/AjaykumarKV/Documents/LLM_Cookbooks/LLM_Examples/Llamaindex_cookbooks/RAG/docs.llamaindex.ai/Advanced Retrieval Strategies - LlamaIndex.html'),\n",
       " WindowsPath('C:/Users/AjaykumarKV/Documents/LLM_Cookbooks/LLM_Examples/Llamaindex_cookbooks/RAG/docs.llamaindex.ai/Building Performant RAG Applications for Production - LlamaIndex.html'),\n",
       " WindowsPath('C:/Users/AjaykumarKV/Documents/LLM_Cookbooks/LLM_Examples/Llamaindex_cookbooks/RAG/docs.llamaindex.ai/index.html'),\n",
       " WindowsPath('C:/Users/AjaykumarKV/Documents/LLM_Cookbooks/LLM_Examples/Llamaindex_cookbooks/RAG/docs.llamaindex.ai/Node Parser Usage Pattern - LlamaIndex.html'),\n",
       " WindowsPath('C:/Users/AjaykumarKV/Documents/LLM_Cookbooks/LLM_Examples/Llamaindex_cookbooks/RAG/docs.llamaindex.ai/Query Transformations - LlamaIndex.html'),\n",
       " WindowsPath('C:/Users/AjaykumarKV/Documents/LLM_Cookbooks/LLM_Examples/Llamaindex_cookbooks/RAG/docs.llamaindex.ai/Usage pattern - LlamaIndex.html')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_html_files = [f for f in all_files if f.suffix.lower() == \".html\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_html_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx 0/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.unstructured.io/general/v0/general \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjaykumarKV\\Documents\\LLM_Cookbooks\\LLM_Examples\\Llamaindex_cookbooks\\RAG\\docs.llamaindex.ai\\Advanced Retrieval Strategies - LlamaIndex.html\n",
      "Idx 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.unstructured.io/general/v0/general \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjaykumarKV\\Documents\\LLM_Cookbooks\\LLM_Examples\\Llamaindex_cookbooks\\RAG\\docs.llamaindex.ai\\Building Performant RAG Applications for Production - LlamaIndex.html\n",
      "Idx 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.unstructured.io/general/v0/general \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjaykumarKV\\Documents\\LLM_Cookbooks\\LLM_Examples\\Llamaindex_cookbooks\\RAG\\docs.llamaindex.ai\\index.html\n",
      "Idx 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.unstructured.io/general/v0/general \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjaykumarKV\\Documents\\LLM_Cookbooks\\LLM_Examples\\Llamaindex_cookbooks\\RAG\\docs.llamaindex.ai\\Node Parser Usage Pattern - LlamaIndex.html\n",
      "Idx 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.unstructured.io/general/v0/general \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjaykumarKV\\Documents\\LLM_Cookbooks\\LLM_Examples\\Llamaindex_cookbooks\\RAG\\docs.llamaindex.ai\\Query Transformations - LlamaIndex.html\n",
      "Idx 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.unstructured.io/general/v0/general \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjaykumarKV\\Documents\\LLM_Cookbooks\\LLM_Examples\\Llamaindex_cookbooks\\RAG\\docs.llamaindex.ai\\Usage pattern - LlamaIndex.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "\n",
    "doc_limit = 100\n",
    "\n",
    "docs = []\n",
    "for idx, f in enumerate(all_html_files):\n",
    "    if idx > doc_limit:\n",
    "        break\n",
    "    print(f\"Idx {idx}/{len(all_html_files)}\")\n",
    "    loaded_docs = reader.load_data(file=f, split_documents=True)\n",
    "    # Hardcoded Index. Everything before this is ToC for all pages\n",
    "    start_idx = 72\n",
    "    loaded_doc = Document(\n",
    "        text=\"\\n\\n\".join([d.get_content() for d in loaded_docs[72:]]),\n",
    "        metadata={\"path\": str(f)},\n",
    "    )\n",
    "    print(loaded_doc.metadata[\"path\"])\n",
    "    docs.append(loaded_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='c75f3056-34dc-42ba-841c-adac1f8d6150', embedding=None, metadata={'path': 'C:\\\\Users\\\\AjaykumarKV\\\\Documents\\\\LLM_Cookbooks\\\\LLM_Examples\\\\Llamaindex_cookbooks\\\\RAG\\\\docs.llamaindex.ai\\\\Advanced Retrieval Strategies - LlamaIndex.html'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='18ae1257-cb9a-4f5b-8a8c-a63cc5710a17', embedding=None, metadata={'path': 'C:\\\\Users\\\\AjaykumarKV\\\\Documents\\\\LLM_Cookbooks\\\\LLM_Examples\\\\Llamaindex_cookbooks\\\\RAG\\\\docs.llamaindex.ai\\\\Building Performant RAG Applications for Production - LlamaIndex.html'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='44639713-5ad8-41c1-9db3-218047ef2828', embedding=None, metadata={'path': 'C:\\\\Users\\\\AjaykumarKV\\\\Documents\\\\LLM_Cookbooks\\\\LLM_Examples\\\\Llamaindex_cookbooks\\\\RAG\\\\docs.llamaindex.ai\\\\index.html'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"LlamaIndex.TS on npm\\n\\nContributing#\\n\\nWe are open-source and always welcome contributions to the project! Check out our contributing guide for full details on how to extend the core library or add an integration to a third party like an LLM, a vector store, an agent tool and more.\\n\\nLlamaIndex Ecosystem#\\n\\nThere's more to the LlamaIndex universe! Check out some of our other projects:\\n\\nllama_deploy | Deploy your agentic workflows as production microservices\\n\\nLlamaHub | A large (and growing!) collection of custom data connectors\\n\\nSEC Insights | A LlamaIndex-powered application for financial research\\n\\ncreate-llama | A CLI tool to quickly scaffold LlamaIndex projects\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='285f232a-2187-48c4-86ff-9298f6f7cf48', embedding=None, metadata={'path': 'C:\\\\Users\\\\AjaykumarKV\\\\Documents\\\\LLM_Cookbooks\\\\LLM_Examples\\\\Llamaindex_cookbooks\\\\RAG\\\\docs.llamaindex.ai\\\\Node Parser Usage Pattern - LlamaIndex.html'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='93ea0bc3-acaf-450c-b8d2-a9ca498b9dda', embedding=None, metadata={'path': 'C:\\\\Users\\\\AjaykumarKV\\\\Documents\\\\LLM_Cookbooks\\\\LLM_Examples\\\\Llamaindex_cookbooks\\\\RAG\\\\docs.llamaindex.ai\\\\Query Transformations - LlamaIndex.html'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e1419543-6a83-41c0-a1cd-3c863ede4298', embedding=None, metadata={'path': 'C:\\\\Users\\\\AjaykumarKV\\\\Documents\\\\LLM_Cookbooks\\\\LLM_Examples\\\\Llamaindex_cookbooks\\\\RAG\\\\docs.llamaindex.ai\\\\Usage pattern - LlamaIndex.html'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "node_parser = SentenceSplitter()\n",
    "for idx, doc in enumerate(tqdm(docs)):\n",
    "        nodes = node_parser.get_nodes_from_documents([doc])\n",
    "        \n",
    "nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
