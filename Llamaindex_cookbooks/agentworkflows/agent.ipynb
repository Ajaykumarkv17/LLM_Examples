{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.11.16)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.3.4)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.16 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.11.16)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.10 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.2.11)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.2.2)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.2.2)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.59.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (3.10.9)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (2024.2.0)\n",
      "Requirement already satisfied: httpx in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (3.2.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index) (0.1.2)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index) (0.5.7)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.13.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.6)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (4.6.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (0.8.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/codespace/.local/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.16->llama-index) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, pypdf\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 5.1.0\n",
      "    Uninstalling pypdf-5.1.0:\n",
      "      Successfully uninstalled pypdf-5.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "instructor 1.7.2 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pypdf-4.3.1 tenacity-8.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-huggingface\n",
      "  Downloading llama_index_llms_huggingface-0.4.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-llms-huggingface) (0.27.1)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-llms-huggingface)\n",
      "  Downloading llama_index_core-0.12.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n",
      "  Downloading text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-llms-huggingface) (2.5.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.48.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (4.12.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.10.9)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.16.0)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.5)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.2.1)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (6.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.13.1)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.22.0)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
      "Downloading llama_index_llms_huggingface-0.4.2-py3-none-any.whl (11 kB)\n",
      "Downloading llama_index_core-0.12.12-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: text-generation, llama-index-core, llama-index-llms-huggingface\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.16\n",
      "    Uninstalling llama-index-core-0.11.16:\n",
      "      Successfully uninstalled llama-index-core-0.11.16\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-embeddings-openai 0.2.5 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index 0.11.16 requires llama-index-core<0.12.0,>=0.11.16, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index-llms-openai 0.2.11 requires llama-index-core<0.12.0,>=0.11.7, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index-readers-file 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.0 requires llama-index-core<0.12.0,>=0.11.13.post1, but you have llama-index-core 0.12.12 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.12 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-core-0.12.12 llama-index-llms-huggingface-0.4.2 text-generation-0.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-llms-huggingface-api\n",
      "  Downloading llama_index_llms_huggingface_api-0.3.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-llms-huggingface-api) (0.27.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-llms-huggingface-api) (0.12.12)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (4.12.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.10.9)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.2.0)\n",
      "Requirement already satisfied: httpx in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/python/3.12.1/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.13.1)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.22.0)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.14.0)\n",
      "Downloading llama_index_llms_huggingface_api-0.3.1-py3-none-any.whl (4.8 kB)\n",
      "Installing collected packages: llama-index-llms-huggingface-api\n",
      "Successfully installed llama-index-llms-huggingface-api-0.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-huggingface\n",
    "%pip install llama-index-llms-huggingface-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.48.0)\n",
      "Requirement already satisfied: huggingface_hub[inference] in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.27.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers[torch]) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers[torch]) (1.2.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub[inference]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface_hub[inference]) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface_hub[inference]) (3.10.9)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[torch]) (6.0.0)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->huggingface_hub[inference]) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->huggingface_hub[inference]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp->huggingface_hub[inference]) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->huggingface_hub[inference]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->huggingface_hub[inference]) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->huggingface_hub[inference]) (1.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers[torch]\" \"huggingface_hub[inference]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "\n",
    "\n",
    "HF_TOKEN: Optional[str] = os.getenv(\"HUGGING_FACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remotely_run = HuggingFaceInferenceAPI(\n",
    "    model_name=\"deepseek-ai/DeepSeek-R1\",\n",
    "    \n",
    "    token=HF_TOKEN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "504 Server Error: Gateway Timeout for url: https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1 (Request ID: aUnsdT)\n\nModel deepseek-ai/DeepSeek-R1 time out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 504 Server Error: Gateway Timeout for url: https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m completion_response \u001b[38;5;241m=\u001b[39m \u001b[43mremotely_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTo infinity, and\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion_response)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/llama_index/llms/huggingface_api/base.py:224\u001b[0m, in \u001b[0;36mHuggingFaceInferenceAPI.complete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, formatted: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    222\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CompletionResponse(\n\u001b[0;32m--> 224\u001b[0m         text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sync_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_output\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2345\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2320\u001b[0m         _set_unsupported_text_generation_kwargs(model, unused_params)\n\u001b[1;32m   2321\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_generation(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2322\u001b[0m             prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   2323\u001b[0m             details\u001b[38;5;241m=\u001b[39mdetails,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2343\u001b[0m             watermark\u001b[38;5;241m=\u001b[39mwatermark,\n\u001b[1;32m   2344\u001b[0m         )\n\u001b[0;32m-> 2345\u001b[0m     \u001b[43mraise_text_generation_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[38;5;66;03m# Parse output\u001b[39;00m\n\u001b[1;32m   2348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:466\u001b[0m, in \u001b[0;36mraise_text_generation_error\u001b[0;34m(http_error)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhttp_error\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Otherwise, fallback to default error\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m http_error\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2315\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2315\u001b[0m     bytes_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2316\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2317\u001b[0m     match \u001b[38;5;241m=\u001b[39m MODEL_KWARGS_NOT_USED_REGEX\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:306\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:477\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 504 Server Error: Gateway Timeout for url: https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1 (Request ID: aUnsdT)\n\nModel deepseek-ai/DeepSeek-R1 time out"
     ]
    }
   ],
   "source": [
    "completion_response = remotely_run.complete(\"To infinity, and\")\n",
    "print(completion_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
