{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.12.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.5 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.12.5)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.3.10)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.63.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.5->llama-index) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (2023.6.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\ajaykumarkv\\appdata\\roaming\\python\\python312\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.13.0,>=0.12.5->llama-index)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.3.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.17)\n",
      "Requirement already satisfied: click in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk>3.8.1->llama-index) (0.4.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.5->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.5->llama-index) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ajaykumarkv\\appdata\\roaming\\python\\python312\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.5->llama-index) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ajaykumarkv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "Successfully installed tenacity-8.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.0 which is incompatible.\n",
      "instructor 1.7.2 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
      "langchain-google-vertexai 2.0.13 requires httpx<0.29.0,>=0.28.0, but you have httpx 0.27.2 which is incompatible.\n",
      "langchain-pinecone 0.2.2 requires aiohttp<3.11,>=3.10, but you have aiohttp 3.11.11 which is incompatible.\n",
      "llama-index-llms-huggingface 0.4.1 requires huggingface-hub<0.24.0,>=0.23.0, but you have huggingface-hub 0.28.1 which is incompatible.\n",
      "open-webui 0.5.12 requires chromadb==0.6.2, but you have chromadb 0.5.23 which is incompatible.\n",
      "open-webui 0.5.12 requires google-generativeai==0.7.2, but you have google-generativeai 0.8.4 which is incompatible.\n",
      "open-webui 0.5.12 requires langchain==0.3.7, but you have langchain 0.3.19 which is incompatible.\n",
      "open-webui 0.5.12 requires langchain-community==0.3.7, but you have langchain-community 0.3.18 which is incompatible.\n",
      "open-webui 0.5.12 requires pypdf==4.3.1, but you have pypdf 5.3.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires aiohttp==3.9.5, but you have aiohttp 3.11.11 which is incompatible.\n",
      "pr-agent 0.2.4 requires boto3==1.33.6, but you have boto3 1.35.53 which is incompatible.\n",
      "pr-agent 0.2.4 requires fastapi==0.111.0, but you have fastapi 0.115.7 which is incompatible.\n",
      "pr-agent 0.2.4 requires google-cloud-aiplatform==1.38.0, but you have google-cloud-aiplatform 1.79.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires google-cloud-storage==2.10.0, but you have google-cloud-storage 2.19.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires google-generativeai==0.8.3, but you have google-generativeai 0.8.4 which is incompatible.\n",
      "pr-agent 0.2.4 requires Jinja2==3.1.2, but you have jinja2 3.1.5 which is incompatible.\n",
      "pr-agent 0.2.4 requires litellm==1.52.12, but you have litellm 1.60.2 which is incompatible.\n",
      "pr-agent 0.2.4 requires openai==1.55.3, but you have openai 1.63.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires pydantic==2.8.2, but you have pydantic 2.9.2 which is incompatible.\n",
      "pr-agent 0.2.4 requires pytest==7.4.0, but you have pytest 8.3.4 which is incompatible.\n",
      "pr-agent 0.2.4 requires tenacity==8.2.3, but you have tenacity 8.5.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires tiktoken==0.8.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "pr-agent 0.2.4 requires uvicorn==0.22.0, but you have uvicorn 0.30.6 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os \n",
    "\n",
    "api_key=os.getenv(\"GITHUB_API_KEY\")\n",
    "tavily_api_key=os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", api_key=api_key,api_base=\"https://models.inference.ai.azure.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"How did india win the world cup 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As of my last knowledge update in October 2023, the 2024 ICC Men's T20 World Cup had not yet taken place, and I do not have information about its outcome. To find out how India won the 2024 World Cup, I recommend checking the latest sports news or official cricket websites for the most current information.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import AsyncTavilyClient\n",
    "\n",
    "\n",
    "async def search_web(query: str) -> str:\n",
    "    \"\"\"Useful for using the web to answer questions.\"\"\"\n",
    "    client = AsyncTavilyClient(api_key=tavily_api_key)\n",
    "    return str(await client.search(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import  AgentWorkflow\n",
    "\n",
    "workflow = AgentWorkflow.from_tools_or_functions(\n",
    "    [search_web],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that can search the web for information.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India won the ICC T20 World Cup 2024 by defeating South Africa in a thrilling final held at the Kensington Oval in Bridgetown, Barbados, on June 29, 2024. India emerged victorious by just 7 runs, marking a significant achievement as they became the first team to win the T20 World Cup without losing a single match throughout the tournament.\n",
      "\n",
      "In the final, India showcased a strong performance, building on their earlier successes in the tournament, including a decisive 68-run victory over England in the semifinals. The win ended a 13-year wait for an ICC Cricket World Cup trophy for India.\n",
      "\n",
      "For more details, you can read the full articles on [Sporting News](https://www.sportingnews.com/in/cricket/news/how-india-won-2024-t20-world-cup-2024/fba73d5f370de244e73a5289) and [Al Jazeera](https://www.aljazeera.com/sports/2024/6/29/india-vs-south-africa-icc-t20-world-cup-final-result-match-report-champions-rohit-markram-bumrah-shamsi).\n"
     ]
    }
   ],
   "source": [
    "response = await workflow.run(user_msg=\"How did india win the world cup 2024?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you, Logan! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(workflow)\n",
    "\n",
    "response = await workflow.run(\n",
    "    user_msg=\"My name is Logan, nice to meet you!\", ctx=ctx\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Logan.\n"
     ]
    }
   ],
   "source": [
    "response = await workflow.run(user_msg=\"What is my name?\", ctx=ctx)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import JsonPickleSerializer, JsonSerializer\n",
    "\n",
    "ctx_dict = ctx.to_dict(serializer=JsonSerializer())\n",
    "\n",
    "restored_ctx = Context.from_dict(\n",
    "    workflow, ctx_dict, serializer=JsonSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I remember your name is Logan.\n"
     ]
    }
   ],
   "source": [
    "response = await workflow.run(\n",
    "    user_msg=\"Do you still remember my name?\", ctx=restored_ctx\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Saskatoon is as follows:\n",
      "\n",
      "- **Temperature**: -3.7°C (25.3°F)\n",
      "- **Condition**: Mist\n",
      "- **Wind**: 6.7 mph (10.8 kph) from the South\n",
      "- **Humidity**: 93%\n",
      "- **Visibility**: 2.4 km (1.0 miles)\n",
      "- **Feels Like**: -8.0°C (17.7°F)\n",
      "\n",
      "For more details, you can check the full report [here](https://www.weatherapi.com/)."
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentInput,\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    "    AgentStream,\n",
    ")\n",
    "\n",
    "handler = workflow.run(user_msg=\"What is the weather in Saskatoon?\")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, AgentStream):\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "        # print(event.response)  # the current full response\n",
    "        # print(event.raw)  # the raw llm api response\n",
    "        # print(event.current_agent_name)  # the current agent name\n",
    "    # elif isinstance(event, AgentInput):\n",
    "    #    print(event.input)  # the current input messages\n",
    "    #    print(event.current_agent_name)  # the current agent name\n",
    "    # elif isinstance(event, AgentOutput):\n",
    "    #    print(event.response)  # the current full response\n",
    "    #    print(event.tool_calls)  # the selected tool calls, if any\n",
    "    #    print(event.raw)  # the raw llm api response\n",
    "    # elif isinstance(event, ToolCallResult):\n",
    "    #    print(event.tool_name)  # the tool name\n",
    "    #    print(event.tool_kwargs)  # the tool kwargs\n",
    "    #    print(event.tool_output)  # the tool output\n",
    "    # elif isinstance(event, ToolCall):\n",
    "    #     print(event.tool_name)  # the tool name\n",
    "    #     print(event.tool_kwargs)  # the tool kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "\n",
    "async def set_name(ctx: Context, name: str) -> str:\n",
    "    state = await ctx.get(\"state\")\n",
    "    state[\"name\"] = name\n",
    "    await ctx.set(\"state\", state)\n",
    "    return f\"Name set to {name}\"\n",
    "\n",
    "\n",
    "workflow = AgentWorkflow.from_tools_or_functions(\n",
    "    [set_name],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that can set a name.\",\n",
    "    initial_state={\"name\": \"unset\"},\n",
    ")\n",
    "\n",
    "ctx = Context(workflow)\n",
    "\n",
    "response = await workflow.run(user_msg=\"My name is Logan\", ctx=ctx)\n",
    "print(str(response))\n",
    "\n",
    "state = await ctx.get(\"state\")\n",
    "print(state[\"name\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
