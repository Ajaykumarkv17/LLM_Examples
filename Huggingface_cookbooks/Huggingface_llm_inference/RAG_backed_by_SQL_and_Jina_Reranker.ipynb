{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pr-agent 0.2.4 requires openai==1.55.3, but you have openai 1.57.4 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU transformers einops llama-index llama-index-postprocessor-jinaai-rerank  llama-index-llms-huggingface \"huggingface_hub[inference]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AjaykumarKV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\AjaykumarKV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\AjaykumarKV\\.cache\\huggingface\\hub\\models--jinaai--jina-reranker-v2-base-multilingual. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual:\n",
      "- configuration_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual:\n",
      "- mlp.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual:\n",
      "- mha.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual:\n",
      "- block.py\n",
      "- mha.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual:\n",
      "- embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual:\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual:\n",
      "- modeling_xlm_roberta.py\n",
      "- mlp.py\n",
      "- block.py\n",
      "- embedding.py\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(1026, 768)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "    )\n",
       "    (emb_drop): Dropout(p=0.1, inplace=False)\n",
       "    (emb_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (mixer): MHA(\n",
       "            (Wqkv): LinearResidual(in_features=768, out_features=2304, bias=True)\n",
       "            (inner_attn): SelfAttention(\n",
       "              (drop): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (inner_cross_attn): CrossAttention(\n",
       "              (drop): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "reranker_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"jinaai/jina-reranker-v2-base-multilingual\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "reranker_model.to(\"cpu\")  # or 'cpu' if no GPU is available\n",
    "reranker_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AjaykumarKV\\AppData\\Local\\Temp\\ipykernel_24432\\3166651729.py:3: DeprecationWarning: Call to deprecated class HuggingFaceInferenceAPI. (Deprecated in favor of `HuggingFaceInferenceAPI` from `llama-index-llms-huggingface-api` which should be used instead.)\n",
      "  mistral_llm = HuggingFaceInferenceAPI(model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", token=api_key)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n",
    "\n",
    "mistral_llm = HuggingFaceInferenceAPI(model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", token=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_declarations = [\n",
    "    \"CREATE TABLE platform (\\n\\tid INTEGER PRIMARY KEY,\\n\\tplatform_name TEXT DEFAULT NULL\\n);\",\n",
    "    \"CREATE TABLE genre (\\n\\tid INTEGER PRIMARY KEY,\\n\\tgenre_name TEXT DEFAULT NULL\\n);\",\n",
    "    \"CREATE TABLE publisher (\\n\\tid INTEGER PRIMARY KEY,\\n\\tpublisher_name TEXT DEFAULT NULL\\n);\",\n",
    "    \"CREATE TABLE region (\\n\\tid INTEGER PRIMARY KEY,\\n\\tregion_name TEXT DEFAULT NULL\\n);\",\n",
    "    \"CREATE TABLE game (\\n\\tid INTEGER PRIMARY KEY,\\n\\tgenre_id INTEGER,\\n\\tgame_name TEXT DEFAULT NULL,\\n\\tCONSTRAINT fk_gm_gen FOREIGN KEY (genre_id) REFERENCES genre(id)\\n);\",\n",
    "    \"CREATE TABLE game_publisher (\\n\\tid INTEGER PRIMARY KEY,\\n\\tgame_id INTEGER DEFAULT NULL,\\n\\tpublisher_id INTEGER DEFAULT NULL,\\n\\tCONSTRAINT fk_gpu_gam FOREIGN KEY (game_id) REFERENCES game(id),\\n\\tCONSTRAINT fk_gpu_pub FOREIGN KEY (publisher_id) REFERENCES publisher(id)\\n);\",\n",
    "    \"CREATE TABLE game_platform (\\n\\tid INTEGER PRIMARY KEY,\\n\\tgame_publisher_id INTEGER DEFAULT NULL,\\n\\tplatform_id INTEGER DEFAULT NULL,\\n\\trelease_year INTEGER DEFAULT NULL,\\n\\tCONSTRAINT fk_gpl_gp FOREIGN KEY (game_publisher_id) REFERENCES game_publisher(id),\\n\\tCONSTRAINT fk_gpl_pla FOREIGN KEY (platform_id) REFERENCES platform(id)\\n);\",\n",
    "    \"CREATE TABLE region_sales (\\n\\tregion_id INTEGER DEFAULT NULL,\\n\\tgame_platform_id INTEGER DEFAULT NULL,\\n\\tnum_sales REAL,\\n   CONSTRAINT fk_rs_gp FOREIGN KEY (game_platform_id) REFERENCES game_platform(id),\\n\\tCONSTRAINT fk_rs_reg FOREIGN KEY (region_id) REFERENCES region(id)\\n);\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def rank_tables(query: str, table_specs: List[str], top_n: int = 0) -> List[Tuple[float, str]]:\n",
    "    \"\"\"\n",
    "    Get sorted pairs of scores and table specifications, then return the top N,\n",
    "    or all if top_n is 0 or default.\n",
    "    \"\"\"\n",
    "    pairs = [[query, table_spec] for table_spec in table_specs]\n",
    "    scores = reranker_model.compute_score(pairs)\n",
    "    scored_tables = [(score, table_spec) for score, table_spec in zip(scores, table_specs)]\n",
    "    scored_tables.sort(key=lambda x: x[0], reverse=True)\n",
    "    if top_n and top_n < len(scored_tables):\n",
    "        return scored_tables[0:top_n]\n",
    "    return scored_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query=\"Identify the top 10 platforms by total sales.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5698526501655579,\n",
       "  'CREATE TABLE region_sales (\\n\\tregion_id INTEGER DEFAULT NULL,\\n\\tgame_platform_id INTEGER DEFAULT NULL,\\n\\tnum_sales REAL,\\n   CONSTRAINT fk_rs_gp FOREIGN KEY (game_platform_id) REFERENCES game_platform(id),\\n\\tCONSTRAINT fk_rs_reg FOREIGN KEY (region_id) REFERENCES region(id)\\n);'),\n",
       " (0.42298123240470886,\n",
       "  'CREATE TABLE platform (\\n\\tid INTEGER PRIMARY KEY,\\n\\tplatform_name TEXT DEFAULT NULL\\n);'),\n",
       " (0.2658804655075073,\n",
       "  'CREATE TABLE game_platform (\\n\\tid INTEGER PRIMARY KEY,\\n\\tgame_publisher_id INTEGER DEFAULT NULL,\\n\\tplatform_id INTEGER DEFAULT NULL,\\n\\trelease_year INTEGER DEFAULT NULL,\\n\\tCONSTRAINT fk_gpl_gp FOREIGN KEY (game_publisher_id) REFERENCES game_publisher(id),\\n\\tCONSTRAINT fk_gpl_pla FOREIGN KEY (platform_id) REFERENCES platform(id)\\n);')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_tables = rank_tables(user_query, table_declarations, top_n=3)\n",
    "ranked_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "make_sql_prompt_tmpl_text = \"\"\"\n",
    "Generate a SQL query to answer the following question from the user:\n",
    "\\\"{query_str}\\\"\n",
    "\n",
    "The SQL query should use only tables with the following SQL definitions:\n",
    "\n",
    "Table 1:\n",
    "{table_1}\n",
    "\n",
    "Table 2:\n",
    "{table_2}\n",
    "\n",
    "Table 3:\n",
    "{table_3}\n",
    "\n",
    "Make sure you ONLY output an SQL query and no explanation.\n",
    "\"\"\"\n",
    "make_sql_prompt_tmpl = PromptTemplate(make_sql_prompt_tmpl_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sql_prompt = make_sql_prompt_tmpl.format(\n",
    "    query_str=user_query, table_1=ranked_tables[0][1], table_2=ranked_tables[1][1], table_3=ranked_tables[2][1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate a SQL query to answer the following question from the user:\n",
      "\"Identify the top 10 platforms by total sales.\"\n",
      "\n",
      "The SQL query should use only tables with the following SQL definitions:\n",
      "\n",
      "Table 1:\n",
      "CREATE TABLE region_sales (\n",
      "\tregion_id INTEGER DEFAULT NULL,\n",
      "\tgame_platform_id INTEGER DEFAULT NULL,\n",
      "\tnum_sales REAL,\n",
      "   CONSTRAINT fk_rs_gp FOREIGN KEY (game_platform_id) REFERENCES game_platform(id),\n",
      "\tCONSTRAINT fk_rs_reg FOREIGN KEY (region_id) REFERENCES region(id)\n",
      ");\n",
      "\n",
      "Table 2:\n",
      "CREATE TABLE platform (\n",
      "\tid INTEGER PRIMARY KEY,\n",
      "\tplatform_name TEXT DEFAULT NULL\n",
      ");\n",
      "\n",
      "Table 3:\n",
      "CREATE TABLE game_platform (\n",
      "\tid INTEGER PRIMARY KEY,\n",
      "\tgame_publisher_id INTEGER DEFAULT NULL,\n",
      "\tplatform_id INTEGER DEFAULT NULL,\n",
      "\trelease_year INTEGER DEFAULT NULL,\n",
      "\tCONSTRAINT fk_gpl_gp FOREIGN KEY (game_publisher_id) REFERENCES game_publisher(id),\n",
      "\tCONSTRAINT fk_gpl_pla FOREIGN KEY (platform_id) REFERENCES platform(id)\n",
      ");\n",
      "\n",
      "Make sure you ONLY output an SQL query and no explanation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_sql_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT platform.platform_name, SUM(region_sales.num_sales) as total_sales\n",
      "FROM region_sales\n",
      "JOIN game_platform ON region_sales.game_platform_id = game_platform.id\n",
      "JOIN platform ON game_platform.platform_id = platform.id\n",
      "GROUP BY platform.platform_name\n",
      "ORDER BY total_sales DESC\n",
      "LIMIT 10;\n"
     ]
    }
   ],
   "source": [
    "response = mistral_llm.complete(make_sql_prompt)\n",
    "sql_query = str(response)\n",
    "print(sql_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
