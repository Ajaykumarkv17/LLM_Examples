{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name=\"deepseek-r1-distill-llama-70b\",streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[90m<\u001b[0m\u001b[90mt\u001b[0m\u001b[90mh\u001b[0m\u001b[90mi\u001b[0m\u001b[90mn\u001b[0m\u001b[90mk\u001b[0m\u001b[90m>\u001b[0m \u001b[90m\n",
      "\u001b[0m\u001b[90m\n",
      "\u001b[0m \u001b[90m<\u001b[0m\u001b[90m/\u001b[0m\u001b[90mt\u001b[0m\u001b[90mh\u001b[0m\u001b[90mi\u001b[0m\u001b[90mn\u001b[0m\u001b[90mk\u001b[0m\u001b[90m>\u001b[0m \u001b[90m\n",
      "\u001b[0m\u001b[90m\n",
      "\u001b[0m \u001b[90mH\u001b[0m\u001b[90me\u001b[0m\u001b[90ml\u001b[0m\u001b[90ml\u001b[0m\u001b[90mo\u001b[0m \u001b[90m!\u001b[0m \u001b[90m \u001b[0m\u001b[90mH\u001b[0m\u001b[90mo\u001b[0m\u001b[90mw\u001b[0m \u001b[90m \u001b[0m\u001b[90mc\u001b[0m\u001b[90ma\u001b[0m\u001b[90mn\u001b[0m \u001b[90m \u001b[0m\u001b[90mI\u001b[0m \u001b[90m \u001b[0m\u001b[90ma\u001b[0m\u001b[90ms\u001b[0m\u001b[90ms\u001b[0m\u001b[90mi\u001b[0m\u001b[90ms\u001b[0m\u001b[90mt\u001b[0m \u001b[90m \u001b[0m\u001b[90my\u001b[0m\u001b[90mo\u001b[0m\u001b[90mu\u001b[0m \u001b[90m \u001b[0m\u001b[90mt\u001b[0m\u001b[90mo\u001b[0m\u001b[90md\u001b[0m\u001b[90ma\u001b[0m\u001b[90my\u001b[0m \u001b[90m?\u001b[0m \u001b[90m \u001b[0m\u001b[90mðŸ˜Š\u001b[0m  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def print_with_effect(text, color='90', delay=0.0001):\n",
    "    for char in text:\n",
    "        sys.stdout.write(f\"\\033[{color}m{char}\\033[0m\")\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(delay)\n",
    "    sys.stdout.write(' ')  # Add a space after each chunk\n",
    "    sys.stdout.flush()\n",
    "\n",
    "for chunk in llm.stream(\"hi\"):\n",
    "    print_with_effect(chunk.content)\n",
    "\n",
    "print()  # Add a newline at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"deepseek-r1:7b\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"human\", \"i need to go out sunday\"),\n",
    "]\n",
    "for chunk in llm.stream(messages):\n",
    "    print_with_effect(chunk.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Great! What do you need help with?\n"
     ]
    }
   ],
   "source": [
    "res=llm.invoke(\"You got it\")\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "together_api_key=os.getenv(\"TOGETHER_API_KEY\")\n",
    "\n",
    "together_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out who won the World Series in 2020. I'm not super familiar with baseball, but I know the World Series is the championship series of Major League Baseball (MLB), played between the American League (AL) and National League (NL) champions. \n",
      "\n",
      "First, I should probably recall if I remember any news from around that time. 2020 was a unique year because of the COVID-19 pandemic, which affected many sports events. I think the baseball season was shortened that year, but they still managed to have a World Series. \n",
      "\n",
      "I remember hearing that the Los Angeles Dodgers were a strong team around that time. They might have won it, but I'm not entirely sure. Alternatively, maybe the New York Yankees or another team like the Houston Astros could have been in the running. Wait, the Astros were involved in a cheating scandal around 2019 or 2020, so maybe they weren't the champions that year.\n",
      "\n",
      "I think the Dodgers have a long history and had some recent success. They might have won the World Series in 2020. Let me try to remember any key players. Clayton Kershaw is a pitcher for the Dodgers, and I think he's been there for a while. Maybe he played a role in their victory.\n",
      "\n",
      "I also recall that the World Series in 2020 was played at a neutral site because of the pandemic, which was different from previous years where the games are held at the home stadiums of the participating teams. I believe it was held in Arlington, Texas, at Globe Life Field, which is the home of the Texas Rangers. That might have been a unique aspect of that year's series.\n",
      "\n",
      "So, putting it together, the Los Angeles Dodgers were likely the winners. They probably defeated an American League team. Maybe the Tampa Bay Rays? I think the Rays were in the World Series around that time. They had a good season but might not have won the championship.\n",
      "\n",
      "To confirm, the 2020 World Series was between the Dodgers and the Rays. The Dodgers won the series, ending a long championship drought. I think it was their first World Series win since 1988, which is a significant gap. That would make the victory especially meaningful for their fans.\n",
      "\n",
      "I don't remember the exact number of games, but I think the series didn't go the full seven games. Maybe the Dodgers won in six games? Or perhaps five? I'm not certain about that detail, but the main point is that the Dodgers were the champions.\n",
      "\n",
      "So, in summary, after considering the teams, the impact of the pandemic, and the neutral location, I conclude that the Los Angeles Dodgers won the 2020 World Series.\n",
      "</think>\n",
      "\n",
      "The Los Angeles Dodgers won the 2020 World Series, defeating the Tampa Bay Rays in the series held at Globe Life Field in Arlington, Texas. This victory marked the Dodgers' first championship since 1988."
     ]
    }
   ],
   "source": [
    "from together import Together\n",
    "\n",
    "client = Together(api_key=together_api_key)\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\",\n",
    "    messages=messages,\n",
    "    \n",
    "    temperature=0.7,\n",
    "    top_p=0.7,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1,\n",
    "    \n",
    "    stream=True\n",
    ")\n",
    "for token in response:\n",
    "    if hasattr(token, 'choices'):\n",
    "        print(token.choices[0].delta.content, end='', flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
