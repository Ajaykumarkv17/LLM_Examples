{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name=\"deepseek-r1-distill-llama-70b\",streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[90m<\u001b[0m\u001b[90mt\u001b[0m\u001b[90mh\u001b[0m\u001b[90mi\u001b[0m\u001b[90mn\u001b[0m\u001b[90mk\u001b[0m\u001b[90m>\u001b[0m \u001b[90m\n",
      "\u001b[0m\u001b[90m\n",
      "\u001b[0m \u001b[90m<\u001b[0m\u001b[90m/\u001b[0m\u001b[90mt\u001b[0m\u001b[90mh\u001b[0m\u001b[90mi\u001b[0m\u001b[90mn\u001b[0m\u001b[90mk\u001b[0m\u001b[90m>\u001b[0m \u001b[90m\n",
      "\u001b[0m\u001b[90m\n",
      "\u001b[0m \u001b[90mH\u001b[0m\u001b[90me\u001b[0m\u001b[90ml\u001b[0m\u001b[90ml\u001b[0m\u001b[90mo\u001b[0m \u001b[90m!\u001b[0m \u001b[90m \u001b[0m\u001b[90mH\u001b[0m\u001b[90mo\u001b[0m\u001b[90mw\u001b[0m \u001b[90m \u001b[0m\u001b[90mc\u001b[0m\u001b[90ma\u001b[0m\u001b[90mn\u001b[0m \u001b[90m \u001b[0m\u001b[90mI\u001b[0m \u001b[90m \u001b[0m\u001b[90ma\u001b[0m\u001b[90ms\u001b[0m\u001b[90ms\u001b[0m\u001b[90mi\u001b[0m\u001b[90ms\u001b[0m\u001b[90mt\u001b[0m \u001b[90m \u001b[0m\u001b[90my\u001b[0m\u001b[90mo\u001b[0m\u001b[90mu\u001b[0m \u001b[90m \u001b[0m\u001b[90mt\u001b[0m\u001b[90mo\u001b[0m\u001b[90md\u001b[0m\u001b[90ma\u001b[0m\u001b[90my\u001b[0m \u001b[90m?\u001b[0m \u001b[90m \u001b[0m\u001b[90mðŸ˜Š\u001b[0m  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def print_with_effect(text, color='90', delay=0.0001):\n",
    "    for char in text:\n",
    "        sys.stdout.write(f\"\\033[{color}m{char}\\033[0m\")\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(delay)\n",
    "    sys.stdout.write(' ')  # Add a space after each chunk\n",
    "    sys.stdout.flush()\n",
    "\n",
    "for chunk in llm.stream(\"hi\"):\n",
    "    print_with_effect(chunk.content)\n",
    "\n",
    "print()  # Add a newline at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"deepseek-r1:7b\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"human\", \"i need to go out sunday\"),\n",
    "]\n",
    "for chunk in llm.stream(messages):\n",
    "    print_with_effect(chunk.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to come up with 10 sentences that end with the word \"apple.\" Hmm, let me think about how to approach this. First, I should understand the requirement clearly. Each sentence must end with \"apple,\" so the last word before the period should be \"apple.\" \n",
      "\n",
      "I guess I can start by brainstorming different contexts where \"apple\" can naturally fit at the end. Maybe talking about eating an apple, picking an apple, or using it in various scenarios. Let me jot down some ideas.\n",
      "\n",
      "1. Maybe something about lunch. Like, \"She packed a sandwich and an apple.\" That works because it ends with \"apple.\"\n",
      "\n",
      "2. Another idea could be about someone giving an apple as a gift. \"He gave his teacher a shiny red apple.\" That ends with \"apple\" too.\n",
      "\n",
      "3. How about a child picking an apple from a tree? \"The child climbed the tree to pick an apple.\" That fits.\n",
      "\n",
      "4. Someone taking a bite of an apple. \"He took a big bite of the juicy apple.\" Ends with \"apple.\"\n",
      "\n",
      "5. Maybe a still life painting including an apple. \"The painting featured a bowl of fruit and an apple.\" That works.\n",
      "\n",
      "6. A teacher using an apple as an example. \"The teacher used a red apple as an example.\" Ends with \"apple.\"\n",
      "\n",
      "7. Someone throwing an apple to a friend. \"He tossed the ripe apple to his friend.\" That's good.\n",
      "\n",
      "8. A person finding an apple in their bag. \"She found a worm in her apple.\" Wait, that ends with \"apple,\" but maybe I can rephrase it to end with \"apple.\" Maybe \"She found a worm in her apple.\" Hmm, that actually ends with \"apple,\" so that's okay.\n",
      "\n",
      "9. Someone drawing an apple. \"The artist carefully drew a still life of an apple.\" That ends with \"apple.\"\n",
      "\n",
      "10. A person smelling an apple. \"The aroma of the ripe apple filled the room.\" That ends with \"apple.\"\n",
      "\n",
      "Wait, let me check each sentence to make sure they all end with \"apple.\" \n",
      "\n",
      "1. Ends with \"apple.\" Good.\n",
      "2. Ends with \"apple.\" Good.\n",
      "3. Ends with \"apple.\" Good.\n",
      "4. Ends with \"apple.\" Good.\n",
      "5. Ends with \"apple.\" Good.\n",
      "6. Ends with \"apple.\" Good.\n",
      "7. Ends with \"apple.\" Good.\n",
      "8. Ends with \"apple.\" Good.\n",
      "9. Ends with \"apple.\" Good.\n",
      "10. Ends with \"apple.\" Perfect.\n",
      "\n",
      "I think that covers it. Each sentence is unique and ends with \"apple.\" I tried to vary the contexts to make them interesting and not repetitive. I hope these sentences meet the requirement.\n",
      "</think>\n",
      "\n",
      "Here are 10 sentences that end with the word \"apple,\" each crafted with a unique context:\n",
      "\n",
      "1. She packed a sandwich and an apple.\n",
      "2. He gave his teacher a shiny red apple.\n",
      "3. The child climbed the tree to pick an apple.\n",
      "4. He took a big bite of the juicy apple.\n",
      "5. The painting featured a bowl of fruit and an apple.\n",
      "6. The teacher used a red apple as an example.\n",
      "7. He tossed the ripe apple to his friend.\n",
      "8. She found a worm in her apple.\n",
      "9. The artist carefully drew a still life of an apple.\n",
      "10. The aroma of the ripe apple filled the room.\n"
     ]
    }
   ],
   "source": [
    "res=llm.invoke(\"Give me 10 sentences that ends with word apple\")\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "together_api_key=os.getenv(\"TOGETHER_API_KEY\")\n",
    "\n",
    "together_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from together import Together\n",
    "\n",
    "client = Together(api_key=together_api_key)\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\",\n",
    "    messages=messages,\n",
    "    \n",
    "    temperature=0.7,\n",
    "    top_p=0.7,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1,\n",
    "    \n",
    "    stream=True\n",
    ")\n",
    "for token in response:\n",
    "    if hasattr(token, 'choices'):\n",
    "        print(token.choices[0].delta.content, end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pinecone_api_key=os.getenv(\"PINECONE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"VOYAGE_API_KEY\"):\n",
    "  os.environ[\"VOYAGE_API_KEY\"] = getpass.getpass(\"Enter API key for Voyage AI: \")\n",
    "\n",
    "\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "\n",
    "embeddings = VoyageAIEmbeddings(model=\"voyage-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = \"my-first\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vector_store = PineconeVectorStore(embedding=embeddings, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['296e4c9f-e429-4cdd-8b2b-8251375ba21f',\n",
       " 'f178c12c-01d1-49aa-b76b-d14270ecb61c',\n",
       " '3ee09035-2a93-4074-b309-feab3e79d289',\n",
       " '1ddc1967-c83d-4f45-b6da-ecc7bb373577',\n",
       " 'd914fcd3-c042-4ea5-8501-8efc94b32861',\n",
       " '77abe69d-ea05-47ea-a1cb-c0d006905c7b',\n",
       " '40b9a2e3-dd5d-422a-8c5b-edbf5d856469',\n",
       " '8ae5c184-aea3-4407-b05e-8234c789263f',\n",
       " '8aa3acc6-03e8-4165-975e-64fc5c11200d',\n",
       " 'a8da632b-9a23-42db-8676-da6ff31a235d']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
