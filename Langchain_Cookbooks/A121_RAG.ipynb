{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Advanced RAG System with AI21's Jamba-1.5-large\n",
    "\n",
    "This notebook demonstrates implementing a Retrieval Augmented Generation (RAG) system using AI21's Jamba-1.5-large language model. Jamba-1.5-large features a 256k token context window, making it highly effective for RAG applications by allowing:\n",
    "\n",
    "- Processing of larger chunks of retrieved content\n",
    "- Better handling of long-form context\n",
    "- More comprehensive document analysis\n",
    "\n",
    "We'll combine this with vector storage and embeddings to create an efficient information retrieval and generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ai21 import ChatAI21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_key=os.getenv(\"AI21_API_KEY\", None)\n",
    "\n",
    "from langchain_ai21 import ChatAI21\n",
    "\n",
    "llm =ChatAI21(model=\"jamba-1.5-large\",api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here are 10 sentences that end with the word \"apple\":\\n\\n1. The red fruit hanging from the tree is a juicy apple.\\n2. She took a bite of the crisp apple.\\n3. The teacher gave each student a shiny apple.\\n4. He bought a basket of fresh apples from the market apple.\\n5. The orchard was filled with rows of apple trees apple.\\n6. For dessert, they served a warm apple pie apple.\\n7. The apple cider was sweet and refreshing apple.\\n8. She made a delicious apple crumble for the party apple.\\n9. The grocery store had a sale on Granny Smith apples apple.\\n10. He planted an apple seed in his backyard, hoping it would grow into a tree apple.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=llm.invoke(\"Give me 10 sentences that only ends in word apple \")\n",
    "\n",
    "a.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_voyageai import VoyageAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api=os.getenv(\"VOYAGE_API_KEY\")\n",
    "\n",
    "\n",
    "embeddings = VoyageAIEmbeddings(model=\"voyage-3\",api_key=api)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = \"my-first\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vector_store = PineconeVectorStore(embedding=embeddings, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Documents into RAG System\n",
    "\n",
    "We'll use the LangChain PDF loader to extract content from PDF documents. While there are several alternatives available:\n",
    "\n",
    "## Document Loading Options\n",
    "- **LangChain PDF Loader(It provides various options like using libraries PYMUPDF,PYPDF,PDFPLUMBER)** (current choice)\n",
    "- LlamaParser\n",
    "- AWS Textract\n",
    "- Azure AI Document Intelligence\n",
    "- Multimodal LLMs (GPT-4V, Gemini Pro Vision)\n",
    "\n",
    "The LangChain PDF loader provides a simple and effective way to extract text content while maintaining document structure and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    \"data/eye_eurp.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/eye_eurp.pdf', 'page': 1, 'page_label': '2'}, page_content=\"2/61 \\nTable of contents \\n \\nKey Takeaways 3 \\nIntroduction - The fundamental guarantees of a digital society 5 \\n1. The technical maturity of facial recognition technologies paves the way for their \\ndeployment 8 \\n1.1. A maturity in line with the dynamics of artificial intelligence technologies 8 \\n1.2. The field of facial recognition encompasses a diversity of uses 10 \\n1.2.1. Varied uses with different levels of risk 10 \\n1.2.2. Overlap with other technologies raises further concerns 14 \\n1.3. Facial recognition technologies are not foolproof 15 \\n1.3.1. The inherent shortcomings of facial recognition technologies 15 \\n1.3.2. A perpetual technological race to correct their negative effects 19 \\n1.3.3. Probabilistic technologies prone to human deficiencies 20 \\n2. An inconsistent and efficient application of the legal framework 22 \\n2.1. Facial recognition technologies are relatively well regulated 22 \\n2.1.1. Fundamental rights are applicable to facial recognition technologies 22 \\n2.1.2. National and regional regulations complete the framework outlined by fundamental \\nrights                                                                   29 \\n2.2. The legal framework suffers from deep weaknesses in its implementation 40 \\n2.2.1. A varied application across member states 40 \\n2.2.2. Enforcement difficulties which lead to inefficiencies 41 \\n3. Towards a European standardization system guaranteeing fundamental rights and \\nfreedoms 46 \\n3.1. The NIST‚Äôs dominance over international standards 46 \\n3.1.1. The reasons for this predominance: an internationally recognized authority without a \\nEuropean equivalent 46 \\n3.1.2. This predominance must be questioned 49 \\n3.2. Making European standards a lever for protecting citizens 50 \\n3.2.1. Accounting for both technical and legal aspects 50 \\n3.2.2. Ensuring the adoption of European standards by enforcing compliance in public \\nprocurement contracts 52 \\n3.3. A European governance dedicated to the standardization of facial recognition technologies 53 \\n3.3.1. Gathering expertise within a multi-stakeholder body 53 \\n3.3.2. Putting auditability at the heart of the standardization system 55 \\nConclusion - The EU's opportunity to place humans at the heart of the system 58 \\n \\n  \")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/week1.pdf', 'page': 0, 'page_label': '1'}, page_content='Copyright Notice\\nThese slides are distributed under the Creative Commons License.\\nDeepLearning.AI makes these slides available for educational purposes. You may not use or \\ndistribute these slides for commercial purposes. You may make copies of these slides and \\nuse or distribute them for educational purposes as long as you cite DeepLearning.AI as the \\nsource of the slides.\\nFor the rest of the details of the license, see \\nhttps://creativecommons.org/licenses/by-sa/2.0/legalcode'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 1, 'page_label': '2'}, page_content='Generative AI & \\nLarge Language \\nModels (LLMs)\\n USE CASES, \\nPROJECT LIFECYCLE, AND \\nMODEL PRE-TRAINING'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 2, 'page_label': '3'}, page_content='Generative AI & \\nLarge Language Model \\nUse Cases & Model \\nLifecycle'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 3, 'page_label': '4'}, page_content='Generative AI & \\nLarge Language Models'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 4, 'page_label': '5'}, page_content=\"Generative AI\\nChatBot\\nThe street layout of \\nWashington D.C. was \\ndesigned by Pierre \\nCharles L'Enfant, a \\nFrench-born American \\narchitect and civil \\nengineer.\\nWho designed the street \\nlayout of Washington DC?\\nT\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 5, 'page_label': '6'}, page_content='Generative AI\\nWhat do you want to create?\\npAIntBox\\nAn imaginary subway map \\nin a coastal city.\\nGenerate\\nImage dimensions:\\n(Max 2048)\\nby'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 6, 'page_label': '7'}, page_content='Generative AI\\n11\\nCodeAId\\ndef binary_search(arr, x, l, r):_\\n   if r >= l:\\n        mid = l + (r - l) // 2\\n        if arr[mid] == x:\\n            return mid\\n        elif arr[mid] > x:\\n            return binary_search(arr, x, l, mid - 1)\\n        else:\\n            return binary_search(arr, x, mid + 1, r)\\n    else:\\n        return -1\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n  < 1/2 >  Accept Tab\\nAI Connected              Run security scan'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 7, 'page_label': '8'}, page_content='Large Language Models\\nBERT\\nGPT\\nFLAN-T5\\nLLaMa\\nPaLM\\nBLOOM'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 8, 'page_label': '9'}, page_content='Large Language Models\\nBERT\\nGPT\\nFLAN-T5\\nLLaMa\\nPaLM\\nBLOOM'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 9, 'page_label': '10'}, page_content='Prompts and completions\\nWhere is Ganymede \\nlocated in the solar \\nsystem? LLM\\nWhere is Ganymede \\nlocated in the solar \\nsystem?\\nGanymede is a moon of \\nJupiter and is located \\nin the solar system \\nwithin Jupiter‚Äôs \\norbit.\\nPrompt CompletionModel\\nContext window\\n‚óè typically a few 1000 \\nwords.'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 10, 'page_label': '11'}, page_content='Prompts and completions'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 11, 'page_label': '12'}, page_content='Use cases & tasks'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 12, 'page_label': '13'}, page_content='LLM chatbot\\nChatBot\\nWho designed the street \\nlayout of Washington DC?\\nT'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 13, 'page_label': '14'}, page_content=\"LLM chatbot\\nChatBot\\nThe street layout of \\nWashington D.C. was \\ndesigned by Pierre \\nCharles L'Enfant, a \\nFrench-born American \\narchitect and civil \\nengineer.\\nWho designed the street \\nlayout of Washington DC?\\nT\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 14, 'page_label': '15'}, page_content='LLM use cases & tasks\\n SummarizationEssay Writing Translation'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 15, 'page_label': '16'}, page_content='LLM use cases & tasks\\n Invoke APIs \\nand actions\\nAction call\\nExternal \\nApplications\\nSummarizationEssay Writing Translation Information \\nretrieval'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 16, 'page_label': '17'}, page_content='BERT*\\n110M\\nBLOOM\\n176B\\n*Bert-base\\nThe signiÔ¨Åcance of scale: language understanding\\nBLOOM\\n176B'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 17, 'page_label': '18'}, page_content='How LLMs work - \\nTransformers architecture'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 18, 'page_label': '19'}, page_content='Generating text with RNNs\\nRNN'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 19, 'page_label': '20'}, page_content='Generating text with RNNs\\nThe milk is bad, my tea tastes great. ? ‚Ä¶ RNN'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 20, 'page_label': '21'}, page_content='Generating text with RNNs\\nThe milk is bad, my tea tastes great. ? ‚Ä¶ RNN'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 21, 'page_label': '22'}, page_content='Generating text with RNNs\\nThe milk is bad, my tea tastes great. ? ‚Ä¶ RNN'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 22, 'page_label': '23'}, page_content='Generating text with RNNs\\nThe milk is bad, my tea tastes great. ? RNN'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 23, 'page_label': '24'}, page_content='Generating text with RNNs\\nThe milk is bad, my tea tastes great. \\n\\udd22\\udd22\\nRNN'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 24, 'page_label': '25'}, page_content='Understanding language can be challenging\\nI took my money to the bank.\\nRiver bank?'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 25, 'page_label': '26'}, page_content='Understanding language can be challenging\\n The teacher taught the student with the book.\\nThe teacher‚Äôs book?\\nThe student‚Äôs book?'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 26, 'page_label': '27'}, page_content='Transformers'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 27, 'page_label': '28'}, page_content='Transformers\\n‚óè Scale efÔ¨Åciently\\n‚óè Parallel process\\n‚óè Attention to input \\nmeaning'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 28, 'page_label': '29'}, page_content='Transformers\\nRNN LLMLLM\\nL'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 29, 'page_label': '30'}, page_content='Transformers\\nThe teacher taught the student with the book.'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 30, 'page_label': '31'}, page_content='Transformers\\nThe teacher taught the student with the book.'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 31, 'page_label': '32'}, page_content='Transformers\\nThe teacher taught the student with the book.'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 32, 'page_label': '33'}, page_content='Self-attention\\nThe\\nteacher\\ntaught\\nthe\\nstudent\\nwith\\na\\nbook\\n.\\nThe\\nteacher\\ntaught\\nthe\\nstudent\\nwith\\na\\nbook\\n.'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 33, 'page_label': '34'}, page_content='Self-attention\\nThe\\nteacher\\ntaught\\nthe\\nstudent\\nwith\\na\\nbook\\n.\\nThe\\nteacher\\ntaught\\nthe\\nstudent\\nwith\\na\\nbook\\n.'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 34, 'page_label': '35'}, page_content='Transformers'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 35, 'page_label': '36'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 36, 'page_label': '37'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 37, 'page_label': '38'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 38, 'page_label': '39'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 39, 'page_label': '40'}, page_content='Transformers\\nthe teacher taught the\\n342 879 432 342Tokenizer T oken IDs\\nInput:\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 40, 'page_label': '41'}, page_content='Transformers\\nthe teach er taught the\\n156 790 321 890 156\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nTokenizer T oken IDs\\nInput:'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 41, 'page_label': '42'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nEmbedding Embedding'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 42, 'page_label': '43'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nEmbedding EmbeddingEmbedding\\nz\\n342 879 432 342\\nX1 X2 X3 X4\\ne.g. 512'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 43, 'page_label': '44'}, page_content='Transformers\\nbook\\ncomputer\\ninternet\\nstudent\\nfox\\nÔ¨Åre'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 44, 'page_label': '45'}, page_content='Transformers\\nbook\\ncomputer\\ninternet\\nstudent\\nfox\\nÔ¨Åre'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 45, 'page_label': '46'}, page_content='Transformers\\nbook\\ncomputer\\ninternet\\nstudent\\nfox\\nÔ¨Åre\\nAngle measures distance \\nbetween words'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 46, 'page_label': '47'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nPositional\\nEncoding\\nPositional\\nEncoding\\nX1 X2 X3 X4\\nX1 X2 X3 X4\\n+\\nT oken \\nembeddings\\nPosition \\nembeddings'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 47, 'page_label': '48'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nSelf-attention Self-attention'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 48, 'page_label': '49'}, page_content='EncoderEncoder\\nTransformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nMulti-headed \\nSelf-attention\\nMulti-headed \\nSelf-attention'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 49, 'page_label': '50'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nFeed forward \\nnetwork\\nFeed forward \\nnetwork'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 50, 'page_label': '51'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nP1 P2 ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ Pn\\nSoftmax\\noutput'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 51, 'page_label': '52'}, page_content=\"Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nTranslation: \\nsequence-to-sequence task\\nJ'aime l'apprentissage \\nautomatique\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 52, 'page_label': '53'}, page_content=\"Transformers\\nTranslation: \\nsequence-to-sequence task\\nJ‚Äôaimel'apprentissage\\nautomatique\\n2345 3425 3853\\nJ'aime l'apprentissage \\nautomatique Encoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 53, 'page_label': '54'}, page_content=\"Transformers\\nTranslation: \\nsequence-to-sequence task\\nJ‚Äôaimel'apprentissage\\nautomatique\\n2345 3425 3853\\nJ'aime l'apprentissage \\nautomatique Encoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 54, 'page_label': '55'}, page_content=\"Transformers\\nTranslation: \\nsequence-to-sequence task\\nJ‚Äôaimel'apprentissage\\nautomatique\\n2345 3425 3853\\nJ'aime l'apprentissage \\nautomatique Encoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 55, 'page_label': '56'}, page_content=\"Transformers\\nTranslation: \\nsequence-to-sequence task\\nJ‚Äôaimel'apprentissage\\nautomatique\\n2345 3425 3853\\nJ'aime l'apprentissage \\nautomatique Encoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 56, 'page_label': '57'}, page_content=\"Transformers\\nTranslation: \\nsequence-to-sequence task\\nJ‚Äôaimel'apprentissage\\nautomatique\\n2345 3425 3853\\nJ'aime l'apprentissage \\nautomatique Encoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\n297\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 57, 'page_label': '58'}, page_content=\"Transformers\\nTranslation: \\nsequence-to-sequence task\\nJ‚Äôaimel'apprentissage\\nautomatique\\n2345 3425 3853\\nJ'aime l'apprentissage \\nautomatique Encoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\n297 450 901 389\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 58, 'page_label': '59'}, page_content=\"Transformers\\nTranslation: \\nsequence-to-sequence task\\nJ‚Äôaimel'apprentissage\\nautomatique\\n2345 3425 3853\\nJ'aime l'apprentissage \\nautomatique Encoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\n297 450 901 389\\nI love machine\\nlearning\\nI love machine \\nlearning\\nüéâ\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 59, 'page_label': '60'}, page_content='Transformers\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput\\nSoftmax \\noutput'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 60, 'page_label': '61'}, page_content='Transformers\\nEncoder\\nEncodes inputs (‚Äúprompts‚Äù) \\nwith contextual understanding \\nand produces one vector per \\ninput token.\\nDecoder \\nAccepts input tokens and \\ngenerates new tokens.\\nEncoder\\nDecoder\\nEmbedding Embedding\\nSoftmax\\noutput\\nInputs\\nOutput'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 61, 'page_label': '62'}, page_content='Transformers\\nDecoder\\nInput\\nOutput\\nDecoder Only \\nModelsEncoder\\nOutput\\nInput\\nEncoder Only \\nModels Encoder\\nDecoder\\nInputs\\nOutput\\nEncoder Decoder \\nModels'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 62, 'page_label': '63'}, page_content='Prompting and \\nprompt engineering'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 63, 'page_label': '64'}, page_content='Prompting and prompt engineering\\nWhere is Ganymede \\nlocated in the solar \\nsystem? LLM\\nWhere is Ganymede \\nlocated in the solar \\nsystem?\\nGanymede is a moon of \\nJupiter and is located \\nin the solar system \\nwithin Jupiter‚Äôs \\norbit.\\nPrompt CompletionModel\\nContext window: typically a \\nfew thousand words'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 64, 'page_label': '65'}, page_content='In-context learning (ICL) - zero shot inference\\nClassify this review:\\nI loved this movie!\\nSentiment: LLM\\nPrompt Model\\nZero-shot inference\\nClassify this review:\\nI loved this movie!\\nSentiment: Positive\\nCompletion'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 65, 'page_label': '66'}, page_content='In-context learning (ICL) - zero shot inference\\nClassify this review:\\nI loved this movie!\\nSentiment:\\nLLM Classify this review:\\nI loved this movie!\\nSentiment: eived a \\nvery nice book review\\nPrompt CompletionModel'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 66, 'page_label': '67'}, page_content='Classify this review:\\nI loved this movie!\\nSentiment: Positive\\nClassify this review:\\nI don‚Äôt like this \\nchair.\\nSentiment:\\nIn-context learning (ICL) - one shot inference\\nPrompt Model\\nLLM Classify this review:\\nI loved this movie!\\nSentiment: Positive\\nClassify this review:\\nI don‚Äôt like this \\nchair.\\nSentiment: Negative\\nCompletion\\nOne-shot inference'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 67, 'page_label': '68'}, page_content='Classify this review:\\nI loved this DVD!\\nSentiment: Positive\\nClassify this review:\\nI don‚Äôt like this \\nchair.\\nSentiment: Positive\\nClassify this review:\\nThis is not great.\\nSentiment: Negative\\nClassify this review:\\nI loved this DVD!\\nSentiment: Positive\\nClassify this review:\\nI don‚Äôt like this \\nchair.\\nSentiment: Negative\\nClassify this review:\\nThis is not great.\\nSentiment:\\nIn-context learning (ICL) - few shot inference\\nPrompt CompletionModel\\nLLM'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 68, 'page_label': '69'}, page_content='Summary of in-context learning (ICL)\\nClassify this review:\\nI loved this movie!\\nSentiment: \\nPrompt // Zero Shot\\nClassify this review:\\nI loved this movie!\\nSentiment: Positive\\nClassify this review:\\nI don‚Äôt like this \\nchair.\\nSentiment:\\nPrompt // One Shot\\nClassify this review:\\nI loved this movie!\\nSentiment: Positive\\nClassify this review:\\nI don‚Äôt like this \\nchair.\\nSentiment: Negative\\nClassify this review:\\nWho would use this \\nproduct?\\nSentiment:\\nPrompt // Few Shot >5 or 6 examples\\nContext Window \\n(few thousand words)'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 69, 'page_label': '70'}, page_content='BERT*\\n110M\\nBLOOM\\n176B\\n*Bert-base\\nThe signiÔ¨Åcance of scale: task ability\\nBLOOM\\n176B'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 70, 'page_label': '71'}, page_content='Generative conÔ¨Åguration\\nparameters for inference'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 71, 'page_label': '72'}, page_content='Generative conÔ¨Åguration - inference parameters \\nSample top K 25\\nSample top P 1\\nEnter your prompt here‚Ä¶\\nInference \\nconÔ¨Åguration \\nparameters\\nSubmit\\nT emperature 0.8\\nMax new tokens 200'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 72, 'page_label': '73'}, page_content='Generative conÔ¨Åguration - max new tokens \\nMax new tokens\\nSample top K 25\\nSample top P 1\\nEnter your prompt here‚Ä¶\\nSubmit\\nT emperature 0.8\\nMax new tokens 200'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 73, 'page_label': '74'}, page_content='Generative conÔ¨Åg - max new tokens\\nEncoder\\nDecoder\\nEmbeddingEmbedding\\nSoftmax\\noutput\\nInputs\\nmax_new_tokens = 100\\nmax_new_tokens = 150\\nmax_new_tokens = 200'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 74, 'page_label': '75'}, page_content='Generative conÔ¨Åg - max new tokens\\nEncoder\\nDecoder\\nEmbeddingEmbedding\\nSoftmax\\noutput\\nInputs\\nmax_new_tokens = 100\\nmax_new_tokens = 200\\nmax_new_tokens = 150\\nStop token'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 75, 'page_label': '76'}, page_content='Encoder\\nDecoder\\nEmbeddingEmbedding\\nSoftmax\\noutput\\nInputs\\ncake\\ndonut\\nbanana\\napple\\n‚Ä¶\\n0.20\\n0.10\\n0.02\\n0.01\\n‚Ä¶\\nGenerative conÔ¨Åg - greedy vs. random sampling\\ngreedy: The word/token with the highest \\nprobability is selected.\\nEncoder\\nDecoder\\nEmbeddingEmbedding\\nSoftmax\\noutput\\nInputs\\ncake\\ndonut\\nbanana\\napple\\n‚Ä¶\\n0.20\\n0.10\\n0.02\\n0.01\\n‚Ä¶\\nrandom(-weighted) sampling: select a token \\nusing a random-weighted strategy across \\nthe probabilities of all tokens.  \\nHere, there is a 20% chance that ‚Äòcake‚Äô will be \\nselected, but ‚Äòbanana‚Äô was actually selected.\\nT oken \\nprobability\\nprob word'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 76, 'page_label': '77'}, page_content='Generative conÔ¨Åguration - top-k and top-p\\nT op-k and top-p sampling\\nSample top K 25\\nSample top P 1\\nEnter your prompt here‚Ä¶\\nSubmit\\nT emperature 0.8\\nMax new tokens 200'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 77, 'page_label': '78'}, page_content='Encoder\\nDecoder\\nEmbeddingEmbedding\\nSoftmax\\noutput\\nInputs\\ncake\\ndonut\\nbanana\\napple\\n‚Ä¶\\n0.20\\n0.10\\n0.02\\n0.01\\n‚Ä¶\\nGenerative conÔ¨Åg - top-k sampling\\ntop-k: select an output from the top-k \\nresults after applying random-weighted \\nstrategy using the probabilities\\nk=3\\nprob word'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 78, 'page_label': '79'}, page_content='Encoder\\nDecoder\\nEmbeddingEmbedding\\nSoftmax\\noutput\\nInputs\\nGenerative conÔ¨Åg - top-p sampling\\ntop-p: select an output using the \\nrandom-weighted strategy with the \\ntop-ranked consecutive results by \\nprobability and with a cumulative \\nprobability <= p.\\ncake\\ndonut\\nbanana\\napple\\n‚Ä¶\\n0.20\\n0.10\\n0.02\\n0.01\\n‚Ä¶\\np = 0.30\\nwordprob'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 79, 'page_label': '80'}, page_content='T emperature \\nGenerative conÔ¨Åguration - temperature \\nSample top K 25\\nSample top P 1\\nEnter your prompt here‚Ä¶\\nSubmit\\nT emperature 0.8\\nMax new tokens 200'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 80, 'page_label': '81'}, page_content='Encoder\\nDecoder\\nEmbeddingEmbedding\\nSoftmax\\noutput\\nInputs\\nGenerative conÔ¨Åg - temperature\\nT emperature \\nsetting\\nStrongly peaked \\nprobability \\ndistribution\\nBroader, Ô¨Çatter \\nprobability \\ndistribution\\napple\\nbanana\\ncake\\ndonut\\n‚Ä¶\\n0.001\\n0.002\\n0.400\\n0.012\\n‚Ä¶\\nCooler temperature (e.g <1)\\napple\\nbanana\\ncake\\ndonut\\n‚Ä¶\\n0.040\\n0.080\\n0.150\\n0.120\\n‚Ä¶\\nHigher temperature (>1)\\nprob word prob word'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 81, 'page_label': '82'}, page_content='Generative AI \\nproject lifecycle'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 82, 'page_label': '83'}, page_content='Generative AI project lifecycle\\nApplication integration\\nOptimize \\nand deploy \\nmodel for \\ninference\\nAugment \\nmodel and \\nbuild LLM- \\npowered \\napplications\\nAdapt and align model \\nPrompt \\nengineering\\nFine-tuning \\nAlign with \\nhuman \\nfeedback\\nEvaluateDeÔ¨Åne the \\nuse case\\nScope\\nChoose an \\nexisting \\nmodel or \\npretrain \\nyour own\\nSelect'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 83, 'page_label': '84'}, page_content='Generative AI project lifecycle\\nApplication integration\\nOptimize \\nand deploy \\nmodel for \\ninference\\nAugment \\nmodel and \\nbuild LLM- \\npowered \\napplications\\nAdapt and align model \\nPrompt \\nengineering\\nFine-tuning \\nAlign with \\nhuman \\nfeedback\\nEvaluateDeÔ¨Åne the \\nuse case\\nScope\\nChoose an \\nexisting \\nmodel or \\npretrain \\nyour own\\nSelect'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 84, 'page_label': '85'}, page_content='Good at many tasks?\\n Invoke APIs \\nand actions\\nAction call\\nExternal \\nApplications\\nSummarizationEssay Writing Translation Information \\nretrieval'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 85, 'page_label': '86'}, page_content='Or good at a single task?\\n Invoke APIs \\nand actions\\nAction call\\nExternal \\nApplications\\nSummarizationEssay Writing Translation Information \\nretrieval'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 86, 'page_label': '87'}, page_content='Generative AI project lifecycle\\nApplication integration\\nOptimize \\nand deploy \\nmodel for \\ninference\\nAugment \\nmodel and \\nbuild LLM- \\npowered \\napplications\\nAdapt and align model \\nPrompt \\nengineering\\nFine-tuning \\nAlign with \\nhuman \\nfeedback\\nEvaluateDeÔ¨Åne the \\nuse case\\nScope\\nChoose an \\nexisting \\nmodel or \\npretrain \\nyour own\\nSelect'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 87, 'page_label': '88'}, page_content='Generative AI project lifecycle\\nApplication integration\\nOptimize \\nand deploy \\nmodel for \\ninference\\nAugment \\nmodel and \\nbuild LLM- \\npowered \\napplications\\nDeÔ¨Åne the \\nuse case\\nScope\\nChoose an \\nexisting \\nmodel or \\npretrain \\nyour own\\nSelect Adapt and align model \\nPrompt \\nengineering\\nFine-tuning \\nAlign with \\nhuman \\nfeedback\\nEvaluate'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 88, 'page_label': '89'}, page_content='Generative AI project lifecycle\\nApplication integration\\nOptimize \\nand deploy \\nmodel for \\ninference\\nAugment \\nmodel and \\nbuild LLM- \\npowered \\napplications\\nDeÔ¨Åne the \\nuse case\\nScope\\nChoose an \\nexisting \\nmodel or \\npretrain \\nyour own\\nSelect Adapt and align model \\nPrompt \\nengineering\\nFine-tuning \\nAlign with \\nhuman \\nfeedback\\nEvaluate'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 89, 'page_label': '90'}, page_content='Generative AI project lifecycle\\nAdapt and align model \\nPrompt \\nengineering\\nFine-tuning \\nAlign with \\nhuman \\nfeedback\\nEvaluate\\nChoose an \\nexisting \\nmodel or \\npretrain \\nyour own\\nSelect\\nDeÔ¨Åne the \\nuse case\\nScope Application integration\\nOptimize \\nand deploy \\nmodel for \\ninference\\nAugment \\nmodel and \\nbuild LLM- \\npowered \\napplications'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 90, 'page_label': '91'}, page_content='Pre-training and \\nscaling laws'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 91, 'page_label': '92'}, page_content='Generative AI project lifecycle\\nDeÔ¨Åne the \\nuse case\\nAdapt and align model Application integration\\nChoose an \\nexisting \\nmodel or \\npretrain \\nyour own\\nPrompt \\nengineering\\nOptimize \\nand deploy \\nmodel for \\ninference\\nAugment \\nmodel and \\nbuild LLM- \\npowered \\napplications\\nFine-tuning \\nAlign with \\nhuman \\nfeedback\\nEvaluate\\nScope Select'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 92, 'page_label': '93'}, page_content='Generative AI project lifecycle\\nDeÔ¨Åne the \\nuse case\\nAdapt and align model Application integration\\nChoose an \\nexisting \\nmodel or \\npretrain \\nyour own\\nPrompt \\nengineering\\nOptimize \\nand deploy \\nmodel for \\ninference\\nAugment \\nmodel and \\nbuild LLM- \\npowered \\napplications\\nFine-tuning \\nAlign with \\nhuman \\nfeedback\\nEvaluate\\nScope Select'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 93, 'page_label': '94'}, page_content='Considerations for choosing a model\\nPretrained\\nLLM \\nCustom\\nLLM \\nFoundation model Train your own model'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 94, 'page_label': '95'}, page_content='Considerations for choosing a model\\nPretrained\\nLLM \\nCustom\\nLLM \\nFoundation model Train your own model'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 95, 'page_label': '96'}, page_content='Model hubs'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 96, 'page_label': '97'}, page_content='Model architectures and pre-training objectives'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 97, 'page_label': '98'}, page_content=\"LLM pre-training at a high level\\nGB - TB - PB \\nof unstructured data\\nLLM\\nModel\\nT oken String T oken \\nID\\nEmbedding / \\nVector Representation\\n'_The' 37 [-0.0513, -0.0584, \\n0.0230, ...]\\n'_teacher' 3145 [-0.0335,  0.0167,  \\n0.0484, ...]\\n'_teaches' 11749 [-0.0151, -0.0516,  \\n0.0309, ...]\\n'_the' 8 [-0.0498, -0.0428,  \\n0.0275, ...]\\n'_student' 1236 [-0.0460,  0.0031,  \\n0.0545, ...]\\n... ... ...\\nVocabulary\\nTEXT[...]\\nTEXT[...]\\nTEXT[...]\\nTEXT[...]\\nTEXT[...]\\nTEXT[...]\\nTEXT[...]\\nTEXT[...]\\nTEXT[...]\\nTEXT[...]\\nData Quality Filter\\nTEXT[...]\\n1-3% of \\noriginal \\ntokens\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 98, 'page_label': '99'}, page_content='Transformers\\nDecoder\\nInput\\nOutput\\nDecoder Only \\nModelsEncoder\\nOutput\\nInput\\nEncoder Only \\nModels Encoder\\nDecoder\\nInputs\\nOutput\\nEncoder Decoder \\nModels'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 99, 'page_label': '100'}, page_content='Autoencoding models\\nEncoder-only\\nLLM\\nMasked Language Modeling (MLM)\\nThe teacher teaches the student\\nObjective: Reconstruct text (\"denoising\")\\nThe teacher <MASK> the student\\nBidirectional context\\nThe teacher \\nteaches the \\nstudent. \\n[...]\\nOriginal text\\n<MASK>\\nteaches'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 100, 'page_label': '101'}, page_content='Good use cases:\\n‚óè Sentiment analysis\\n‚óè Named entity recognition\\n‚óè Word classiÔ¨Åcation\\nAutoencoding models\\nExample models:\\n‚óè BERT\\n‚óè ROBERTA'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 101, 'page_label': '102'}, page_content='Autoregressive models\\nDecoder-only\\nLLM\\nCausal Language Modeling (CLM)\\nThe teacher ?\\nObjective: Predict next token\\nThe teacher teaches\\nUnidirectional context\\nThe teacher \\nteaches the \\nstudent. \\n[...]\\nOriginal text\\nThe ? \\nThe teacher'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 102, 'page_label': '103'}, page_content='Good use cases:\\n‚óè T ext generation\\n‚óè Other emergent behavior \\n‚óã Depends on model size\\nExample models:\\n‚óè GPT\\n‚óè BLOOM\\nAutoregressive models'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 103, 'page_label': '104'}, page_content='Sequence-to-sequence models\\nEncoder-Decoder\\nLLM\\nSpan Corruption\\nThe teacher <X> student\\nObjective: Reconstruct span\\n<x> teaches the\\nThe teacher teaches the student\\nSentinel token\\nThe teacher \\nteaches the \\nstudent. \\n[...]\\nOriginal text\\n<MASK><MASK>'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 104, 'page_label': '105'}, page_content='Sequence-to-sequence models\\nGood use cases:\\n‚óè Translation\\n‚óè T ext summarization\\n‚óè Question answering\\nExample models:\\n‚óè T5\\n‚óè BART'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 105, 'page_label': '106'}, page_content='Model architectures and pre-training objectives\\nT arget\\nThe teacher \\nteaches the \\nstudent \\n[...]\\nOriginal text\\nMLM\\nLLM\\nEncoder-only\\nThe teacher \\n<MASK> the \\nstudent\\nThe teacher \\nteaches the \\nstudent\\nAutoencoding:\\nCLM\\nThe teacher ? The teacher \\nteachesLLM\\nDecoder-onlyAutoregressive:\\nThe teacher \\n<X> student\\nSpan corruption\\n<X> teaches theLLM\\nEncoder-DecoderSeq-to-Seq:'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 106, 'page_label': '107'}, page_content='BERT*\\n110M\\nBLOOM\\n176B\\n*Bert-base\\nThe signiÔ¨Åcance of scale: task ability\\nBLOOM\\n176B'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 107, 'page_label': '108'}, page_content='Model size vs. time\\n2018\\nBERT-L\\n340M GPT-2\\n1.5B GPT-3\\n175B PaLM\\n540B\\n20232022\\nGrowth powered by:\\n‚óè Introduction of \\ntransformer\\n‚óè Access to massive \\ndatasets\\n‚óè More powerful \\ncompute resources'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 108, 'page_label': '109'}, page_content='Model size vs. time\\n2018\\nBERT-L\\n340M GPT-2\\n1.5B GPT-3\\n175B PaLM\\n540B\\nincrease?\\n20232022\\nTrillion(s)'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 109, 'page_label': '110'}, page_content='Computational challenges'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 110, 'page_label': '111'}, page_content='Approximate GPU RAM needed to store 1B parameters\\nSources:  https://huggingface.co/docs/transformers/v4.20.1/en/perf_train_gpu_one#anatomy-of-models-memory, https://github.com/facebookresearch/bitsandbytes\\n1 parameter = 4 bytes (32-bit Ô¨Çoat)\\n1B parameters = 4 x 109 bytes = 4GB\\n4GB @ 32-bit\\nfull precision'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 111, 'page_label': '112'}, page_content='Additional GPU RAM needed to train 1B parameters\\nSources:  https://huggingface.co/docs/transformers/v4.20.1/en/perf_train_gpu_one#anatomy-of-models-memory, https://github.com/facebookresearch/bitsandbytes\\n Bytes per parameter\\nModel Parameters (Weights) 4 bytes per parameter\\nAdam optimizer (2 states) +8 bytes per parameter\\nGradients +4 bytes per parameter\\nActivations and \\ntemp memory (variable size)\\n+8 bytes per parameter (high-end estimate)\\nTOTAL =4 bytes per parameter\\n+20 extra bytes per parameter\\n~20 extra bytes \\nper parameter'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 112, 'page_label': '113'}, page_content='Approximate GPU RAM needed to train 1B-params\\nMemory needed to store model\\n4GB @ 32-bit\\nfull precision\\n24GB @ 32-bit\\nfull precision\\nMemory needed to train  model'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 113, 'page_label': '114'}, page_content='Quantization \\n32-bit Ô¨Çoating point\\n16-bit Ô¨Çoating point | 8-bit integer \\n0.0\\n0\\nMIN\\n-3e38\\nMAX\\n+3e38\\nRange:\\nFrom -3e38  to  +3e38\\n? ?\\nFP32\\nFP16 | BFLOAT16 | INT8'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 114, 'page_label': '115'}, page_content=\"Quantization: FP32\\n0.0\\n0\\n3.1415920257568359375\\nX 0        10000000        10010010000111111011000\\nSign\\n1 bit\\nExponent\\n8 bits\\nFraction\\n23 bits\\nMIN\\n-3e38\\nMAX\\n+3e38\\nLet's store Pi: 3.141592\\nMantissa / SigniÔ¨Åcand\\n= Precision\\nFP32\\nReal value of Pi:\\n3.1415926535897932384\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 115, 'page_label': '116'}, page_content=\"Quantization: FP16\\n0.0\\n0MIN\\n-65504 \\nMAX\\n65504\\n3.140625\\nX\\nMIN\\n-3e38\\nMAX\\n+3e38\\n3.1415920257568359375\\nX\\nExponent\\n5 bits\\nFraction\\n10 bits\\nSign\\n1 bit\\n0        10000000        10010010000111111011000\\nSign\\n1 bit\\nExponent\\n8 bits\\nFraction\\n23 bits\\nFP32\\n  0        10000                1001001000\\nFP16  \\nLet's store Pi: 3.141592\\n4 bytes memory\\n2 bytes memory\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 116, 'page_label': '117'}, page_content='Quantization: BFLOAT16\\n0.0\\n0\\nBFLOAT16 | BF16 \\n  0        10000000        1001001\\nSign\\n1 bit\\nExponent\\n8 bits\\nFraction\\n7 bits\\nMIN\\n-3e38\\nMAX\\n+3e38\\nMIN\\n~ -3e38\\nMAX\\n~ +3e38\\n3.140625\\nX\\n3.1415920257568359375\\nX 0        10000000        10010010000111111011000\\nSign\\n1 bit\\nExponent\\n8 bits\\nFraction\\n23 bits\\nFP32\\nLet\\'s store Pi: 3.141592\\n\"Truncated FP32\"\\n4 bytes memory\\n2 bytes memory'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 117, 'page_label': '118'}, page_content=\"Quantization: INT8\\n0.0\\n0MIN\\n-128 \\nMAX\\n127\\n3\\nX\\nMIN\\n-3e38\\nMAX\\n+3e38\\nINT8 \\n0                                        0000011\\n3.1415920257568359375\\nX\\nFraction\\n7 bitsSign\\n1 bit\\n0        10000000        10010010000111111011000\\nSign\\n1 bit\\nExponent\\n8 bits\\nFraction\\n23 bits\\nFP32\\nLet's store Pi: 3.141592\\n4 bytes memory\\n1 byte memory\"),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 118, 'page_label': '119'}, page_content='Quantization: Summary\\n Bits Exponent Fraction Memory needed \\nto store one value\\nFP32 32 8 23 4 bytes\\nFP16 16 5 10 2 bytes\\nBFLOAT16 16 8 7 2 bytes\\nINT8 8 ‚Äì/‚Äì 7 1 byte\\n‚óè Reduce required memory to store and train models\\n‚óè Projects original 32-bit Ô¨Çoating point numbers into lower precision spaces\\n‚óè Quantization-aware training (QAT) learns the quantization scaling factors during training\\n‚óè BFLOAT16 is a popular choice\\nFLAN\\nT5'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 119, 'page_label': '120'}, page_content='Approximate GPU RAM needed to store 1B parameters\\nSources:  https://huggingface.co/docs/transformers/v4.20.1/en/perf_train_gpu_one#anatomy-of-models-memory, https://github.com/facebookresearch/bitsandbytes\\n4GB @ 32-bit\\nfull precision\\nFull-\\nprecision\\nmodel\\n2GB @ 16-bit\\nhalf precision\\n16-bit\\nquantized \\nmodel\\n1GB @ 8-bit\\nprecision\\n8-bit\\nquantized \\nmodel'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 120, 'page_label': '121'}, page_content='GPU RAM needed to train larger models\\n1B param \\nmodel\\n4,200 GB @ 32-bit\\nfull precision\\n12,000 GB @ 32-bit\\nfull precision\\n175B param \\nmodel\\n500B param \\nmodel'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 121, 'page_label': '122'}, page_content='GPU RAM needed to train larger models\\n1B param \\nmodel\\n4,200 GB @ 32-bit\\nfull precision\\n12,000 GB @ 32-bit\\nfull precision\\n175B param \\nmodel\\n500B param \\nmodel\\nAs model sizes get larger, you will \\nneed to split your model across \\nmultiple GPUs for training'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 122, 'page_label': '123'}, page_content='EfÔ¨Åcient Multi-GPU \\nCompute Strategies'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 123, 'page_label': '124'}, page_content='When to use distributed compute\\nLLM LLM\\nModel too big for single GPU Model Ô¨Åts on GPU, train data in \\nparallel'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 124, 'page_label': '125'}, page_content='Distributed Data Parallel (DDP)\\nDataloader\\nGPU 0\\nGPU 1\\nGPU 2\\nGPU 3\\nLLM\\nLLM\\nLLM\\nLLM\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nSynchronize\\ngradients\\nSynchronize\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModel'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 125, 'page_label': '126'}, page_content='Fully Sharded Data Parallel (FSDP)\\n‚óè Motivated by the ‚ÄúZeRO‚Äù paper - zero data overlap between GPUs\\nSources:  \\nRajbhandari et al. 2019: ‚ÄúZeRO: Memory Optimizations T oward Training Trillion Parameter Models‚Äù\\nZhao et al. 2023: ‚ÄúPyT orch FSDP: Experiences on Scaling Fully Sharded Data Parallel‚Äù'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 126, 'page_label': '127'}, page_content='Recap: Additional GPU RAM needed for training\\nSources:  https://huggingface.co/docs/transformers/v4.20.1/en/perf_train_gpu_one#anatomy-of-models-memory, https://github.com/facebookresearch/bitsandbytes\\n Bytes per parameter\\nModel Parameters (Weights) 4 bytes per parameter\\nAdam optimizer (2 states) +8 bytes per parameter\\nGradients +4 bytes per parameter\\nActivations and \\ntemp memory (variable size)\\n+8 bytes per parameter (high-end estimate)\\nTOTAL =4 bytes per parameter\\n+20 extra bytes per parameter'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 127, 'page_label': '128'}, page_content='Memory usage in DDP\\n‚óè One full copy of model and training parameters on each GPU\\nSources:  \\nRajbhandari et al. 2019: ‚ÄúZeRO: Memory Optimizations T oward Training Trillion Parameter Models‚Äù\\nZhao et al. 2023: ‚ÄúPyT orch FSDP: Experiences on Scaling Fully Sharded Data Parallel‚Äù'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 128, 'page_label': '129'}, page_content='Zero Redundancy Optimizer (ZeRO)\\n‚óè Reduces memory by distributing (sharding) the model parameters, \\ngradients, and optimizer states across GPUs\\nModel ‚Äúshard‚Äù: \\nsubset of parameters \\nfor each GPU\\nSources:  \\nRajbhandari et al. 2019: ‚ÄúZeRO: Memory Optimizations T oward Training Trillion Parameter Models‚Äù\\nZhao et al. 2023: ‚ÄúPyT orch FSDP: Experiences on Scaling Fully Sharded Data Parallel‚Äù'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 129, 'page_label': '130'}, page_content='Zero Redundancy Optimizer (ZeRO)\\n‚óè Reduces memory by distributing (sharding) the model parameters, \\ngradients, and optimizer states across GPUs\\nZeRO Stage 1\\nZeRO Stage 2\\nZeRO Stage 3\\nSources:  \\nRajbhandari et al. 2019: ‚ÄúZeRO: Memory Optimizations T oward Training Trillion Parameter Models‚Äù\\nZhao et al. 2023: ‚ÄúPyT orch FSDP: Experiences on Scaling Fully Sharded Data Parallel‚Äù'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 130, 'page_label': '131'}, page_content='Distributed Data Parallel (DDP)\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nSynchronize\\ngradients\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModelDataloader\\nGPU 0\\nGPU 1\\nGPU 2\\nGPU 3\\nLLM\\nLLM\\nLLM\\nLLM'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 131, 'page_label': '132'}, page_content='Distributed Data Parallel (DDP)\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nSynchronize\\ngradients\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModelDataloader\\nGPU 0\\nGPU 1\\nGPU 2\\nGPU 3'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 132, 'page_label': '133'}, page_content='Fully Sharded Data Parallel (FSDP)\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nSynchronize\\ngradients\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModelDataloader\\nGPU 0\\nGPU 1\\nGPU 2\\nGPU 3'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 133, 'page_label': '134'}, page_content='Fully Sharded Data Parallel (FSDP)\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nForward/ \\nBackward pass\\nSynchronize\\ngradients\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModel\\nUpdate\\nModelDataloader\\nGPU 0\\nGPU 1\\nGPU 2\\nGPU 3'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 134, 'page_label': '135'}, page_content='Fully Sharded Data Parallel (FSDP)\\nForward\\npass\\nForward \\npass\\nForward\\npass\\nForward\\npass\\nSynchronize\\ngradients\\nUpdate\\nmodel\\nUpdate\\nmodel\\nUpdate\\nmodel\\nUpdate\\nmodelDataloader\\nGPU 0\\nGPU 1\\nGPU 2\\nGPU 3\\nGet \\nweights\\nBackward \\npass\\nBackward \\npass\\nBackward \\npass\\nBackward\\n pass\\nGet \\nweights'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 135, 'page_label': '136'}, page_content='Fully Sharded Data Parallel (FSDP)\\nForward\\npass\\nForward \\npass\\nForward\\npass\\nForward\\npass\\nSynchronize\\ngradients\\nUpdate\\nmodel\\nUpdate\\nmodel\\nUpdate\\nmodel\\nUpdate\\nmodelDataloader\\nGPU 0\\nGPU 1\\nGPU 2\\nGPU 3\\nGet \\nweights\\nBackward \\npass\\nBackward \\npass\\nBackward \\npass\\nBackward\\n pass\\nGet \\nweights'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 136, 'page_label': '137'}, page_content='Fully Sharded Data Parallel (FSDP)\\n‚óè Helps to reduce overall GPU memory utilization\\n‚óè Supports ofÔ¨Çoading to CPU if needed\\n‚óè ConÔ¨Ågure level of sharding via sharding factor \\nmax. number of GPUs1 GPU\\nFull replication (no sharding)\\nmax. number of GPUs1 GPU\\nFull sharding\\nmax. number of GPUs1 GPU\\nHybrid sharding'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 137, 'page_label': '138'}, page_content='Impact of using FSDP\\nZhao et al. 2023: ‚ÄúPyT orch FSDP: Experiences on Scaling Fully Sharded Data Parallel‚Äù\\nNote: 1 teraFLOP/s = 1,000,000,000,000 \\n(one trillion) Ô¨Çoating point operations per second'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 138, 'page_label': '139'}, page_content='Scaling laws and compute-optimal models'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 139, 'page_label': '140'}, page_content='Scaling choices for pre-training\\nModel \\nperformance\\n(minimize loss)\\nCONSTRAINT: \\nCompute budget \\n(GPUs, training time, cost) \\nSCALING CHOICE: \\nDataset size \\n(number of tokens)\\nSCALING CHOICE: \\nModel size \\n(number of parameters)\\nGoal: maximize model \\nperformance'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 140, 'page_label': '141'}, page_content='Compute budget for training LLMs\\n1 ‚ÄúpetaÔ¨Çop/s-day‚Äù = \\n# Ô¨Çoating point operations performed at rate of 1 petaFLOP per second for one day\\nNVIDIA V100s\\n1 petaÔ¨Çop/s-day  is these chips \\nrunning at full efÔ¨Åciency for 24 hours \\nNote: 1 petaFLOP/s = 1,000,000,000,000,000 \\n(one quadrillion) Ô¨Çoating point operations per second'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 141, 'page_label': '142'}, page_content='Compute budget for training LLMs\\n1 ‚ÄúpetaÔ¨Çop/s-day‚Äù = \\n# Ô¨Çoating point operations performed at rate of 1 petaFLOP per second for one day\\nNVIDIA V100s\\nNVIDIA A100s\\n1 petaÔ¨Çop/s-day  is these chips \\nrunning at full efÔ¨Åciency for 24 hours \\nOR'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 142, 'page_label': '143'}, page_content='Number of petaÔ¨Çop/s-days to pre-train various LLMs\\nSource: Brown et al. 2020, ‚ÄúLanguage Models are Few-Shot Learners‚Äù\\nT5 GPT-3BERT/\\nROBERTA\\nTraining PetaÔ¨Çop/s-days 10000\\n1000\\n100\\n10\\n1\\nBase\\nLarge\\nRo-Base\\nRo-Large\\nSmall\\nBase\\nLarge\\n 3B\\n11B\\nSmall\\nMedium\\nLarge\\n XL\\n2.7B\\n6.7B\\n13B\\n175B'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 143, 'page_label': '144'}, page_content='Compute budget vs. model performance\\nCOMPUTE \\nBUDGET \\nDATASET \\nSIZE\\nMODEL\\nSIZE\\nSource: Kaplan et al. 2020, ‚ÄúScaling Laws for Neural Language Models‚Äù'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 144, 'page_label': '145'}, page_content='Dataset size and model size vs. performance\\nSource: Kaplan et al. 2020, ‚ÄúScaling Laws for Neural Language Models‚Äù \\nCOMPUTE \\nBUDGET \\nDATASET \\nSIZE\\nCOMPUTE \\nBUDGET \\nDATASET \\nSIZE\\nMODEL\\nSIZE\\nCompute resource constraints\\n‚óè Hardware\\n‚óè Project timeline\\n‚óè Financial budget\\n‚ùÑ'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 145, 'page_label': '146'}, page_content='Dataset size and model size vs. performance\\nSource: Kaplan et al. 2020, ‚ÄúScaling Laws for Neural Language Models‚Äù \\nCOMPUTE \\nBUDGET \\nDATASET \\nSIZE\\nCOMPUTE \\nBUDGET \\nDATASET \\nSIZE\\nMODEL\\nSIZE\\n‚ùÑ\\n‚ùÑ\\n‚ùÑ'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 146, 'page_label': '147'}, page_content='Chinchilla paper\\nJordan et al. 2022'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 147, 'page_label': '148'}, page_content='‚óè Very large models may be over-parameterized and under-trained\\nCompute optimal models\\nDATASET \\nSIZE\\nCOMPUTE \\nBUDGET \\nMODEL\\nSIZE\\nFixed\\nCOMPUTE \\nBUDGET \\nMODEL\\nSIZE\\nFixed\\nOver-parameterized Under-trained\\n‚óè Smaller models trained on more data could perform as well as large models\\nDATASET \\nSIZE'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 148, 'page_label': '149'}, page_content='Compute-optimal*\\n# of tokens (~20x)\\n~1.4T\\n~1.3T\\n~3.5T\\n~3.5T\\n~3.5T\\nActual\\n# tokens\\n1.4T\\n1.4T\\n300B\\n180B\\n350B\\nChinchilla scaling laws for model and dataset size \\nSources:  Hoffmann et al. 2022, ‚ÄúTraining Compute-Optimal Large Language Models‚Äù\\nT ouvron et al. 2023, ‚ÄúLLaMA: Open and EfÔ¨Åcient Foundation Language Models‚Äù\\n# of parameters\\n70B\\n65B\\n175B\\n175B\\n176B\\nModel\\nChinchilla\\nLLaMA-65B\\nGPT-3\\nOPT-175B\\nBLOOM\\n* assuming models are trained to be \\ncompute-optimal per Chinchilla paper\\nCompute optimal training datasize \\nis ~20x number of parameters'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 149, 'page_label': '150'}, page_content='Model size vs. time\\n2018\\nBERT-L\\n340M GPT-2\\n1.5B GPT-3\\n175B PaLM\\n540B\\nincrease?\\n20232022\\nTrillion(s)\\nBloombergGPT\\n50B\\ndecrease?\\nLLaMa\\n65B'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 150, 'page_label': '151'}, page_content='Pre-training for domain adaptation'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 151, 'page_label': '152'}, page_content='Pre-training for domain adaptation\\nLegal language'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 152, 'page_label': '153'}, page_content='Pre-training for domain adaptation\\nThe prosecutor had difficulty \\nproving mens rea, as the defendant \\nseemed unaware that his actions \\nwere illegal.\\nThe judge dismissed the case, \\nciting the principle of res \\njudicata as the issue had already \\nbeen decided in a previous trial.\\nDespite the signed agreement, the \\ncontract was invalid as there was \\nno consideration exchanged between \\nthe parties.\\nLegal language'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 153, 'page_label': '154'}, page_content='Pre-training for domain adaptation\\nThe prosecutor had difficulty \\nproving mens rea, as the defendant \\nseemed unaware that his actions \\nwere illegal.\\nThe judge dismissed the case, \\nciting the principle of res \\njudicata as the issue had already \\nbeen decided in a previous trial.\\nDespite the signed agreement, the \\ncontract was invalid as there was \\nno consideration exchanged between \\nthe parties.\\nAfter a strenuous workout, the \\npatient experienced severe myalgia \\nthat lasted for several days.\\nAfter the biopsy, the doctor \\nconfirmed that the tumor was \\nmalignant and recommended immediate \\ntreatment.\\nSig: 1 tab po qid pc & hs\\nT ake one tablet by mouth four times a day, \\nafter meals, and at bedtime.\\nLegal language Medical language'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 154, 'page_label': '155'}, page_content='BloombergGPT: domain adaptation for Ô¨Ånance\\nFinancial\\n(Public & Private)~51%\\nOther\\n(Public)~49%'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 155, 'page_label': '156'}, page_content='BloombergGPT relative to other LLMs\\nSource: Wu et al. 2023, ‚ÄúBloombergGPT: A Large Language Model for Finance‚Äù'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 156, 'page_label': '157'}, page_content='Key takeaways'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 157, 'page_label': '158'}, page_content='LLM use cases & tasks\\n Invoke APIs \\nand actions\\nAction call\\nExternal \\nApplications\\nSummarizationEssay Writing Translation Information \\nretrieval'),\n",
       " Document(metadata={'source': 'data/week1.pdf', 'page': 158, 'page_label': '159'}, page_content='Generative AI project lifecycle\\nApplication integration\\nOptimize \\nand deploy \\nmodel for \\ninference\\nAugment \\nmodel and \\nbuild LLM- \\npowered \\napplications\\nAdapt and align model \\nPrompt \\nengineering\\nFine-tuning \\nAlign with \\nhuman \\nfeedback\\nEvaluateDeÔ¨Åne the \\nuse case\\nScope\\nChoose an \\nexisting \\nmodel or \\npretrain \\nyour own\\nSelect')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
